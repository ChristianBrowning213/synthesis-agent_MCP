# PROJECT CONTEXT DUMP
# Root: F:\Github\synthesis-agent_MCP
# Generated: 2026-02-03 18:11:49
# Notes: Hidden paths and common junk/binaries are skipped. Sizes > max-size are skipped.
#
# Included files will follow with clear section headers.



================================================================================
=== FILE: project_context.txt ===
================================================================================

```

```


================================================================================
=== FILE: project_to_txt.py ===
================================================================================

```python
#!/usr/bin/env python3
from __future__ import annotations   # ‚Üê must be here (first statement)

import argparse, os, sys, time, io
from pathlib import Path
from typing import Optional

DEFAULT_EXCLUDED_DIRS = {
    ".git", ".hg", ".svn", ".idea", ".vscode", ".venv",
    "__pycache__", "node_modules", "dist", "build", ".cache",
    ".mypy_cache", ".pytest_cache", ".next", ".turbo", ".parcel-cache"
}
DEFAULT_EXCLUDED_EXTS = {
    # archives & binaries 
    ".zip", ".gz", ".bz2", ".xz", ".7z", ".rar", ".tar",
    ".exe", ".dll", ".so", ".dylib", ".bin", ".dat", ".lock",
    # media
    ".png", ".jpg", ".jpeg", ".gif", ".webp", ".ico", ".svg",
    ".mp4", ".mov", ".avi", ".mkv", ".mp3", ".wav", ".flac",
    # docs likely huge or non-text
    ".pdf", ".psd", ".ai"
}
DEFAULT_EXCLUDED_FILES = {
    # huge / noisy lock or cache files (still text, but not helpful)
    "package-lock.json", "pnpm-lock.yaml", "yarn.lock",
    "poetry.lock", "pipfile.lock", ".DS_Store", "Thumbs.db"
}

LANG_BY_EXT = {
    ".py": "python", ".js": "javascript", ".ts": "typescript",
    ".tsx": "tsx", ".jsx": "jsx", ".json": "json", ".yml": "yaml",
    ".yaml": "yaml", ".md": "markdown", ".toml": "toml",
    ".ini": "", ".cfg": "", ".conf": "", ".txt": "",
    ".html": "html", ".css": "css", ".scss": "scss", ".sass": "sass",
    ".sh": "bash", ".ps1": "powershell", ".sql": "sql", ".xml": "xml",
    ".java": "java", ".c": "c", ".h": "c", ".cpp": "cpp", ".hpp": "cpp",
    ".rs": "rust", ".go": "go", ".rb": "ruby", ".php": "php",
    ".ipynb": "json"
}

def looks_binary(sample: bytes) -> bool:
    if b"\x00" in sample:
        return True
    # Heuristic: if >30% bytes are non-text-ish, treat as binary
    text_bytes = b"\t\n\r\f\b" + bytes(range(32, 127))
    if not sample:
        return False
    nontext = sum(ch not in text_bytes for ch in sample)
    return (nontext / len(sample)) > 0.30


def read_text_file(path: Path, max_bytes: int) -> Optional[str]:  # üëà change here
    try:
        with path.open("rb") as f:
            sample = f.read(min(max_bytes, 4096))
            if looks_binary(sample):
                return None
        with path.open("rb") as f:
            data = f.read(max_bytes)
        text = data.decode("utf-8", errors="replace")
        return text.replace("\r\n", "\n").replace("\r", "\n")
    except Exception:
        return None


def is_hidden(p: Path) -> bool:
    # Treat names starting with '.' as hidden (works cross-platform)
    return any(part.startswith(".") and part not in {".", ".."} for part in p.parts)

def should_skip_file(p: Path, args, rel: Path) -> bool:
    name = p.name
    if not args.include_dotfiles and (name.startswith(".") or is_hidden(rel)):
        return True
    if name in args.exclude_files or name in DEFAULT_EXCLUDED_FILES:
        return True
    ext = p.suffix.lower()
    if ext in DEFAULT_EXCLUDED_EXTS or ext in args.exclude_exts:
        return True
    if args.include_exts and ext not in args.include_exts:
        return True
    try:
        size = p.stat().st_size
        if size > args.max_size_mb * 1024 * 1024:
            return True
    except Exception:
        return True
    return False

def should_skip_dir(dirpath: Path, args, rel: Path) -> bool:
    name = dirpath.name
    if not args.include_dotfiles and (name.startswith(".") or is_hidden(rel)):
        return True
    if name in DEFAULT_EXCLUDED_DIRS or name in args.exclude_dirs:
        return True
    return False

def main():
    ap = argparse.ArgumentParser(
        description="Concatenate a project‚Äôs text source into one TXT for agent context."
    )
    ap.add_argument("root", help="Project root directory.")
    ap.add_argument("-o", "--output", default="project_context.txt",
                    help="Output TXT path (default: project_context.txt)")
    ap.add_argument("--max-size-mb", type=int, default=2,
                    help="Skip files larger than this many MB (default: 2)")
    ap.add_argument("--include-dotfiles", action="store_true",
                    help="Include dotfiles and hidden paths (default: skip)")
    ap.add_argument("--include-exts", default="", help="Comma-separated whitelist of extensions (e.g., .py,.md)")
    ap.add_argument("--exclude-exts", default="", help="Comma-separated extra excluded extensions (e.g., .log,.csv)")
    ap.add_argument("--exclude-dirs", default="",
                    help="Comma-separated extra excluded dir names (exact match)")
    ap.add_argument("--exclude-files", default="",
                    help="Comma-separated extra excluded file names (exact match)")
    ap.add_argument("--no-fences", action="store_true",
                    help="Do not wrap contents in Markdown code fences.")
    args = ap.parse_args()

    root = Path(args.root).resolve()
    if not root.exists() or not root.is_dir():
        print(f"Error: {root} is not a directory.", file=sys.stderr)
        sys.exit(1)

    # Parse lists
    args.include_exts = {e.strip().lower() for e in args.include_exts.split(",") if e.strip()} if args.include_exts else set()
    args.exclude_exts = {e.strip().lower() for e in args.exclude_exts.split(",") if e.strip()} if args.exclude_exts else set()
    args.exclude_dirs = {d.strip() for d in args.exclude_dirs.split(",") if d.strip()} if args.exclude_dirs else set()
    args.exclude_files = {f.strip() for f in args.exclude_files.split(",") if f.strip()} if args.exclude_files else set()

    included_files = []
    skipped = {"dir": 0, "hidden": 0, "size": 0, "binary": 0, "ext": 0, "other": 0}

    out_path = Path(args.output).resolve()
    out_path.parent.mkdir(parents=True, exist_ok=True)

    with io.open(out_path, "w", encoding="utf-8", newline="\n") as out:
        # Header / manifest preface
        ts = time.strftime("%Y-%m-%d %H:%M:%S")
        out.write(f"# PROJECT CONTEXT DUMP\n")
        out.write(f"# Root: {root}\n# Generated: {ts}\n")
        out.write("# Notes: Hidden paths and common junk/binaries are skipped. Sizes > max-size are skipped.\n")
        out.write("#\n# Included files will follow with clear section headers.\n\n")

        # Walk
        for dirpath, dirnames, filenames in os.walk(root):
            dirpath = Path(dirpath)
            rel_dir = dirpath.relative_to(root)

            # Filter directories in-place (os.walk respects modifications)
            keep_dirs = []
            for d in dirnames:
                dpath = dirpath / d
                if should_skip_dir(dpath, args, rel_dir / d):
                    skipped["dir"] += 1
                    continue
                keep_dirs.append(d)
            dirnames[:] = keep_dirs

            # Files
            for fn in filenames:
                fpath = dirpath / fn
                rel = fpath.relative_to(root)
                if should_skip_file(fpath, args, rel):
                    # heuristic reason counting
                    name = fpath.name
                    if not args.include_dotfiles and (name.startswith(".") or is_hidden(rel)):
                        skipped["hidden"] += 1
                    elif fpath.suffix.lower() in DEFAULT_EXCLUDED_EXTS or fpath.suffix.lower() in args.exclude_exts:
                        skipped["ext"] += 1
                    else:
                        try:
                            if fpath.stat().st_size > args.max_size_mb * 1024 * 1024:
                                skipped["size"] += 1
                            else:
                                skipped["other"] += 1
                        except Exception:
                            skipped["other"] += 1
                    continue

                # Read and binary check
                with fpath.open("rb") as fb:
                    sample = fb.read(4096)
                if looks_binary(sample):
                    skipped["binary"] += 1
                    continue

                text = read_text_file(fpath, max_bytes=args.max_size_mb * 1024 * 1024)
                if text is None:
                    skipped["other"] += 1
                    continue

                included_files.append(str(rel))

                # Write section
                lang = LANG_BY_EXT.get(fpath.suffix.lower(), "")
                out.write("\n\n" + "=" * 80 + "\n")
                out.write(f"=== FILE: {rel} ===\n")
                out.write("=" * 80 + "\n\n")
                if args.no_fences:
                    out.write(text)
                else:
                    fence = lang if lang is not None else ""
                    out.write(f"```{fence}\n{text}\n```\n")

        # Manifest footer
        out.write("\n\n" + "#" * 80 + "\n")
        out.write("# MANIFEST\n")
        out.write("# Included files:\n")
        for p in included_files:
            out.write(f"#  - {p}\n")
        out.write("#\n# Skips summary:\n")
        for k, v in skipped.items():
            out.write(f"#  {k}: {v}\n")
        out.write("# END\n")

    print(f"Done. Wrote: {out_path}")
    print(f"Included files: {len(included_files)} | Skips: {skipped}")
    return 0

if __name__ == "__main__":
    sys.exit(main())

```


================================================================================
=== FILE: pyproject.toml ===
================================================================================

```toml
[project]
name = "synthesis-agent"
version = "0.1.0"
description = "SKY - Synthesis Knowledge Yield Agent for materials synthesis discovery"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "ase>=3.26.0",
    "h5py>=3.14.0",
    "mace-torch>=0.3.14",
    "matminer>=0.9.3",
    "mp-api>=0.45.8",
    "pymatgen>=2025.6.14",
    "typer>=0.17.0",
    "rich>=14.0.0",
    "openai>=1.0.0",
    "monty>=2025.0.0",
    "python-dotenv>=1.0.0",
    "jupyterlab>=4.4.7",
    "mcp>=1.11.0,<2",
]

[project.scripts]
sky = "sky.cli.main:main"
sky-mcp = "sky_mcp.server:main"

[project.optional-dependencies]
dev = [
    "pytest>=7",
    "pytest-asyncio>=0.23",
]

[tool.setuptools]
packages = ["sky", "sky.cli", "sky.core", "sky.report", "src", "src.utils", "sky_mcp"]

```


================================================================================
=== FILE: README.md ===
================================================================================

```markdown
# SKY - Synthesis Analysis Agent

**SKY** is an **LLM-powered agent** for materials synthesis analysis and recommendation.  
It leverages **similarity search on synthesis recipes** from the [Materials Project](https://materialsproject.org/) database to help researchers discover related compounds, structures, and synthesis pathways.

![SKY overview](figs/img.png)

> [!NOTE]
> The demo video is available at here: [Demo](https://www.youtube.com/watch?v=ffLqLH87yLo)

---

## üöÄ Features

- üîç **Composition-based similarity search** ‚Äì find materials with similar chemical formulas.  
- üèóÔ∏è **Structure-based similarity search** ‚Äì identify related compounds by crystal structure.  
- üìú **Synthesis recipe retrieval** ‚Äì access known synthesis procedures for materials.  
- üìä **Property lookup** ‚Äì fetch summaries and structural data from the Materials Project.  
- ü§ñ **LLM-enhanced synthesis recommendations** ‚Äì analyze and recommend synthesis recipes from similar materials using AI reasoning.

---

## üõ†Ô∏è Installation

```bash
# Clone repository
git clone <repository-url>
cd synthesis-agent

# Install dependencies (requires Python 3.11+)
uv sync

# Set up environment variables (MP_API_KEY, OPENAI_API_KEY)
cp .env.example .env
```

> ‚ö†Ô∏è You will need a valid [Materials Project API key](https://materialsproject.org/open) (`MP_API_KEY`) and an OpenAI API key (`OPENAI_API_KEY`).

---

## üìí Quick Start

Check out the tutorial notebook for a hands-on introduction:  
üëâ [tutorial.ipynb](tutorial.ipynb)

---

## üß∞ CLI (sky)

After installation, the SKY CLI is available as the `sky` command:

```bash
# Verify environment and data
sky setup

# Composition-based search
sky search Fe2O3

# Structure-based search from a CIF file
sky search path/to/material.cif

# Interactive chat mode
sky chat

# Show help
sky --help
```

Note: SKY uses OPENAI_API_KEY (or OPENAI_MDG_API_KEY) and optionally MP_API_KEY from your environment.

---

## MCP Server (stdio)

Run the MCP server for general AI tool use:

```bash
uv run sky-mcp
# or
python -m sky_mcp.server
```

### MCP tools

Canonical CIF-text tools (portable across clients):
- `read_cif(cif: str)`
- `search_similar_by_structure_cif(cif: str, top_n: int = 10)`

Local-only convenience tools:
- `read_cif_path(cif_path: str)`
- `search_similar_by_structure_path(cif_path: str, top_n: int = 10)`

Other tools:
- `capabilities()`
- `self_check()`
- `search_similar_by_composition(formula: str, top_n: int = 10)`
- `get_material_properties(material_ids: list[str])`
- `get_synthesis_recipes(formula: str, max_recipes: int = 5)`
- `analyze_synthesis_parameters(text: str)`
- `recursive_synthesis_search(formula: str, max_depth: int = 3, min_confidence: float = 0.7, n_initial_neighbors: int = 30)`
- `discover_synthesis_report(query: str, html: bool = false)` (expensive, networked, nondeterministic)

### Environment variables
- `MP_API_KEY` (required for Materials Project data)
- `OPENAI_API_KEY` or `OPENAI_MDG_API_KEY` (required for `discover_synthesis_report`)
- `SKY_MCP_MAX_FILE_BYTES` (override max local file size; default 2,000,000 bytes)
- `SKY_MCP_ALLOWED_ROOTS` (extra allowed roots for local-only path tools; os.pathsep-separated)

### Assets
Similarity tools require embedding assets under `assets/embedding/*.h5`.

### Local-only path safety
Local-only path tools are restricted to allowed roots (repo root, assets directory, and current working directory by default).

---

### Usage 1: Find similar materials by **composition**

```python
from src.agent import SynthesisAgent

# Initialize agent
agent = SynthesisAgent()

# Find similar materials by composition
results = agent.find_similar_materials_by_composition("Fe2O3", n_neighbors=5)
print(results)
```

---

### Usage 2: Find similar materials by **structure**

```python
from pymatgen.core import Structure
from src.agent import SynthesisAgent

# Initialize agent
agent = SynthesisAgent()

# Load structure file
structure = Structure.from_file("material.cif")

# Structure-based similarity search
results = agent.find_similar_materials_by_structure(structure, n_neighbors=5)
print(results)

# Get synthesis recipes for a formula
recipes = agent.get_synthesis_recipes_by_formula("Fe2O3")
print(recipes)
```

---

## ‚öôÔ∏è Core API

### `SynthesisAgent` (src/agent.py)

```python
from src.agent import SynthesisAgent
from pymatgen.core import Structure

# Initialize agent (requires MP_API_KEY)
agent = SynthesisAgent()

# --- Composition-based similarity search ---
results = agent.find_similar_materials_by_composition("Fe2O3", n_neighbors=5)
# Returns: list[Neighbor] with {material_id, formula, distance, confidence}

# --- Structure-based similarity search ---
structure = Structure.from_file("material.cif")
results = agent.find_similar_materials_by_structure(structure, n_neighbors=5)

# --- Synthesis recipes ---
recipes = agent.get_synthesis_recipes_by_formula("Fe2O3")
# Returns: list[SynthesisRecipe] from Materials Project

# --- Material properties ---
summary = agent.get_summarydoc_by_material_id("mp-1234")
structure = agent.get_structure_by_material_id("mp-1234")
```

---

## üìÇ Project Structure

```text
synthesis-agent/
‚îÇ‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ agent.py         # Core SynthesisAgent API
‚îÇ   ‚îú‚îÄ‚îÄ utils/           # Helper functions
‚îÇ‚îÄ‚îÄ tutorial.ipynb       # Quick start tutorial
‚îÇ‚îÄ‚îÄ .env.example         # Environment variable template
‚îÇ‚îÄ‚îÄ README.md            # Project documentation
```

---

## üîë Environment Variables

Create a `.env` file based on `.env.example`:

```bash
MP_API_KEY=your_materials_project_api_key
OPENAI_API_KEY=your_openai_api_key
```

---

## üìö References

- [Materials Project](https://materialsproject.org/)  
- [pymatgen](https://pymatgen.org/)  
- [OpenAI API](https://platform.openai.com/)  

---

## üìú License

This project is licensed under the **MIT License**.  
See the [LICENSE](LICENSE) file for details.

```


================================================================================
=== FILE: requirements.txt ===
================================================================================

```
# SKY - Requirements for materials synthesis exploration and ML capabilities

# Core Materials Science Libraries
ase>=3.26.0                    # Atomic Simulation Environment for structure manipulation
pymatgen>=2025.6.14           # Materials analysis and crystal structure processing
matminer>=0.9.3               # Feature generation for materials ML
mp-api>=0.45.8                # Materials Project API client
mace-torch>=0.3.14            # MACE ML potential for structure embeddings
monty>=2025.0.0               # Materials-specific utilities and serialization

# Data Processing and ML
h5py>=3.14.0                  # HDF5 file format for embedding storage
numpy>=1.21.0                 # Numerical computing
scikit-learn>=1.0.0           # Machine learning algorithms (nearest neighbors)
pandas>=1.3.0                 # Data manipulation (implicit dependency)

# OpenAI Agents SDK
openai>=1.107.1,<2            # OpenAI API client
agents @ file:///openai-agents-python  # Go to https://github.com/openai/openai-agents-python to install OpenAI Agents Python SDK
pydantic>=2.10,<3             # Data validation and serialization
griffe>=1.5.6,<2              # Python code inspection
typing-extensions>=4.12.2,<5  # Extended type annotations
requests>=2.0,<3              # HTTP requests
types-requests>=2.0,<3        # Type stubs for requests

# CLI and User Interface
typer>=0.17.0                 # CLI framework with rich integration
rich>=14.0.0                  # Rich text and beautiful formatting
click>=8.0.0                  # Command line interface creation (typer dependency)

# Configuration and Environment
python-dotenv>=1.0.0          # Environment variable management

# Materials Project Database Integration
emmet-core>=0.40.0            # Materials Project data models

# Optional Dependencies for Enhanced Features
# Uncomment if you need these capabilities:

# Jupyter Integration (for notebook demos)
# jupyter>=1.0.0
# jupyterlab>=3.0.0
# ipywidgets>=7.6.0

# Visualization (if using visualization features)
# plotly>=5.0.0
# dash>=2.0.0
# matplotlib>=3.5.0

# Advanced ML Features
# tensorflow>=2.8.0           # If using TensorFlow-based models
# torch>=1.12.0               # PyTorch (required by mace-torch)

# Development Dependencies (uncomment for development)
# pytest>=7.0.0
# pytest-asyncio>=0.21.0
# black>=22.0.0
# isort>=5.10.0
# mypy>=1.0.0
# ruff>=0.0.280

# Voice and Realtime Features (if using OpenAI Agents voice features)
# websockets>=15.0,<16
# sounddevice>=0.4.0
# numpy>=2.2.0,<3             # Required for voice features

# Database Features (if using SQLAlchemy session management)
# SQLAlchemy>=2.0
# asyncpg>=0.29.0
# aiosqlite>=0.21.0

# Web Features (if building web interfaces)
# fastapi>=0.110.0,<1
# uvicorn>=0.18.0

# Visualization with Graphviz
# graphviz>=0.17

# Model Context Protocol (Python 3.10+)
# mcp>=1.11.0,<2              # Uncomment if using MCP features on Python 3.10+
```


================================================================================
=== FILE: tutorial.ipynb ===
================================================================================

```json
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e057872",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2818967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pymatgen.core import Composition, Structure\n",
    "from mp_api.client import MPRester\n",
    "from src.search_api import SearchAPI\n",
    "from src.embedding import InputType\n",
    "from src.agent import SynthesisAgent\n",
    "\n",
    "\n",
    "MP_API_KEY = os.getenv(\"MP_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab38407a",
   "metadata": {},
   "source": [
    "# Search API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ee56c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MP dataset from /home/hyunsoo/VScodeProjects/synthesis-agent/assets/embedding/mp_dataset_composition_magpie.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyunsoo/VScodeProjects/synthesis-agent/.venv/lib/python3.11/site-packages/matminer/utils/data.py:326: UserWarning: MagpieData(impute_nan=False):\n",
      "In a future release, impute_nan will be set to True by default.\n",
      "                    This means that features that are missing or are NaNs for elements\n",
      "                    from the data source will be replaced by the average of that value\n",
      "                    over the available elements.\n",
      "                    This avoids NaNs after featurization that are often replaced by\n",
      "                    dataset-dependent averages.\n",
      "  warnings.warn(f\"{self.__class__.__name__}(impute_nan=False):\\n\" + IMPUTE_NAN_WARNING)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Neighbor(neighbor_index=0, material_id='mp-25386', formula='Li(FeO2)2', distance=1.6858739404357614e-07, confidence=0.9999999438042035),\n",
       " Neighbor(neighbor_index=1, material_id='mp-752935', formula='Li(FeO2)2', distance=1.6858739404357614e-07, confidence=0.9999999438042035),\n",
       " Neighbor(neighbor_index=2, material_id='mp-1178108', formula='Li(FeO2)2', distance=1.6858739404357614e-07, confidence=0.9999999438042035),\n",
       " Neighbor(neighbor_index=3, material_id='mp-771057', formula='Li(FeO2)2', distance=1.6858739404357614e-07, confidence=0.9999999438042035),\n",
       " Neighbor(neighbor_index=4, material_id='mp-773043', formula='Li(FeO2)2', distance=1.6858739404357614e-07, confidence=0.9999999438042035),\n",
       " Neighbor(neighbor_index=5, material_id='mp-1178106', formula='Li(FeO2)2', distance=1.6858739404357614e-07, confidence=0.9999999438042035),\n",
       " Neighbor(neighbor_index=6, material_id='mp-771135', formula='Li(FeO2)2', distance=1.6858739404357614e-07, confidence=0.9999999438042035),\n",
       " Neighbor(neighbor_index=7, material_id='mp-1178122', formula='Li(FeO2)2', distance=1.6858739404357614e-07, confidence=0.9999999438042035),\n",
       " Neighbor(neighbor_index=8, material_id='mp-771571', formula='Li(FeO2)2', distance=1.6858739404357614e-07, confidence=0.9999999438042035),\n",
       " Neighbor(neighbor_index=9, material_id='mp-754803', formula='Li(FeO2)2', distance=1.6858739404357614e-07, confidence=0.9999999438042035),\n",
       " Neighbor(neighbor_index=10, material_id='mp-1178103', formula='Li(FeO2)2', distance=1.6858739404357614e-07, confidence=0.9999999438042035),\n",
       " Neighbor(neighbor_index=11, material_id='mp-771396', formula='Li4(FeO2)9', distance=0.26344608180906465, confidence=0.9159299778702668),\n",
       " Neighbor(neighbor_index=12, material_id='mp-752476', formula='Li3(FeO2)5', distance=0.4399305392926217, confidence=0.8636017852737156),\n",
       " Neighbor(neighbor_index=13, material_id='mp-762529', formula='Li2(FeO2)5', distance=0.4850470671394753, confidence=0.8507113852385557),\n",
       " Neighbor(neighbor_index=14, material_id='mp-1120820', formula='Li2Fe4O7', distance=0.49878923070830444, confidence=0.8468234251988423)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_api_comp = SearchAPI(input_type=InputType.COMPOSITION, max_neighbors=100)\n",
    "search_api_comp.query(Composition(\"LiFe2O4\"), n_neighbors=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c90f95b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MP dataset from /home/hyunsoo/VScodeProjects/synthesis-agent/assets/embedding/mp_dataset_structure_mace.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving MaterialsDoc documents: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 3994.58it/s]\n",
      "/home/hyunsoo/VScodeProjects/synthesis-agent/.venv/lib/python3.11/site-packages/mace/calculators/mace.py:197: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  torch.load(f=model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using medium MPA-0 model as default MACE-MP model, to use previous (before 3.10) default model please specify 'medium' as model argument\n",
      "Using Materials Project MACE for MACECalculator with /home/hyunsoo/.cache/mace/macempa0mediummodel\n",
      "Using float32 for MACECalculator, which is faster but less accurate. Recommended for MD. Use float64 for geometry optimization.\n",
      "Using head default out of ['default']\n",
      "Default dtype float32 does not match model dtype float64, converting models to float32.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Neighbor(neighbor_index=0, material_id='mp-19017', formula='LiFePO4', distance=4.2799288166861515e-06, confidence=0.9999985733580787),\n",
       " Neighbor(neighbor_index=1, material_id='mp-18951', formula='LiFePO4', distance=2.201819896697998, confidence=0.48001402077158545),\n",
       " Neighbor(neighbor_index=2, material_id='mp-705312', formula='LiFePO4', distance=2.233734130859375, confidence=0.47493465937517404),\n",
       " Neighbor(neighbor_index=3, material_id='mp-831160', formula='LiFePO4', distance=2.266953706741333, confidence=0.46970462674098623),\n",
       " Neighbor(neighbor_index=4, material_id='mp-849430', formula='Li8MnFe7(PO4)8', distance=2.5171642303466797, confidence=0.43211879355914085)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_api_st = SearchAPI(input_type=InputType.STRUCTURE, max_neighbors=100)\n",
    "mpr = MPRester(MP_API_KEY)\n",
    "structure = mpr.get_structure_by_material_id(\"mp-19017\")  # LiFePO4\n",
    "search_api_st.query(structure, n_neighbors=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f052b826",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1544777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MP dataset from /home/hyunsoo/VScodeProjects/synthesis-agent/assets/embedding/mp_dataset_composition_magpie.h5\n",
      "Loading MP dataset from /home/hyunsoo/VScodeProjects/synthesis-agent/assets/embedding/mp_dataset_structure_mace.h5\n"
     ]
    }
   ],
   "source": [
    "agent = SynthesisAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "502d29e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyunsoo/VScodeProjects/synthesis-agent/.venv/lib/python3.11/site-packages/matminer/utils/data.py:326: UserWarning: MagpieData(impute_nan=False):\n",
      "In a future release, impute_nan will be set to True by default.\n",
      "                    This means that features that are missing or are NaNs for elements\n",
      "                    from the data source will be replaced by the average of that value\n",
      "                    over the available elements.\n",
      "                    This avoids NaNs after featurization that are often replaced by\n",
      "                    dataset-dependent averages.\n",
      "  warnings.warn(f\"{self.__class__.__name__}(impute_nan=False):\\n\" + IMPUTE_NAN_WARNING)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Neighbor(neighbor_index=0, material_id='mp-759319', formula='Li3Fe5O12', distance=0.5145681494852192, confidence=0.8423811318558403),\n",
       " Neighbor(neighbor_index=1, material_id='mp-758559', formula='Li3Fe5O12', distance=0.5145681494852192, confidence=0.8423811318558403),\n",
       " Neighbor(neighbor_index=2, material_id='mp-755806', formula='Li3Fe5O12', distance=0.5145681494852192, confidence=0.8423811318558403),\n",
       " Neighbor(neighbor_index=3, material_id='mp-772179', formula='Li4Fe5Co3O16', distance=0.8141480678092642, confidence=0.7623247070908341),\n",
       " Neighbor(neighbor_index=4, material_id='mp-771396', formula='Li4(FeO2)9', distance=0.8247286466229046, confidence=0.7596408304858411),\n",
       " Neighbor(neighbor_index=5, material_id='mp-759569', formula='Li2Fe2Co3O10', distance=0.8287946298288815, confidence=0.7586119655814628)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors = agent.find_similar_materials_by_composition(\"LiFe2O5\", n_neighbors=6)\n",
    "neighbors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synthesis-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

```


================================================================================
=== FILE: figs\recipy.ipynb ===
================================================================================

```json
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0484a0a4",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Segoe UI', 'Arial', sans-serif; background: linear-gradient(90deg, #00b894 0%, #0984e3 100%); border-radius: 18px; padding: 36px 28px 20px 28px; box-shadow: 0 4px 24px #b2bec3; margin-bottom: 28px; color: #fff; position: relative; overflow: hidden;\">\n",
    "  <div style=\"position: absolute; top: 18px; right: 32px; font-size: 2.5em; opacity: 0.18;\">üî¨</div>\n",
    "  <h1 style=\"font-size: 2.8em; font-weight: 800; margin-bottom: 0.2em; letter-spacing: 1.5px; text-shadow: 1px 2px 8px #636e72;\">Synthesis Report: <span style=\"color: #ffeaa7;\">Material Recipe</span></h1>\n",
    "  <hr style=\"border: 1.5px solid #ffeaa7; margin: 16px 0 22px 0;\">\n",
    "  <div style=\"font-size: 1.18em; color: #dff9fb; margin-bottom: 10px;\">\n",
    "    <b>Date:</b> 12 September 2025<br>\n",
    "    <b>Prepared by:</b> <span style=\"color: #fdcb6e;\">[Your Name or Team]</span>\n",
    "  </div>\n",
    "  <div style=\"font-size: 1.22em; color: #fff; margin-top: 20px;\">\n",
    "    <span style=\"background: rgba(0,0,0,0.08); border-radius: 8px; padding: 6px 12px;\">This report details the <b>cutting-edge synthesis procedure</b> for the target material. Explore the innovative recipe, curated precursors, and advanced structure analysis below. <span style=\"color: #fdcb6e;\">#MaterialsRevolution</span></span>\n",
    "  </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5166c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9514d781",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Segoe UI', 'Arial', sans-serif; margin-bottom: 28px;\">\n",
    "  <h2 style=\"color: #00b894; font-size: 1.7em; font-weight: 700; display: flex; align-items: center; gap: 10px;\">üß™ 1. Precursors</h2>\n",
    "  <p style=\"font-size: 1.12em; color: #444;\">All chemicals and materials required for synthesis, with purity, supplier, and special handling notes.</p>\n",
    "  <table style=\"border-collapse: collapse; width: 100%; font-size: 1.08em; background: #f9fafc; box-shadow: 0 2px 8px #dfe6e9; border-radius: 10px; overflow: hidden;\">\n",
    "    <thead style=\"background: #dff9fb;\">\n",
    "      <tr>\n",
    "        <th style=\"border: 1px solid #00b894; padding: 10px;\">Precursor Name</th>\n",
    "        <th style=\"border: 1px solid #00b894; padding: 10px;\">Chemical Formula</th>\n",
    "        <th style=\"border: 1px solid #00b894; padding: 10px;\">Purity (%)</th>\n",
    "        <th style=\"border: 1px solid #00b894; padding: 10px;\">Supplier</th>\n",
    "        <th style=\"border: 1px solid #00b894; padding: 10px;\">Notes</th>\n",
    "      </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "      <tr>\n",
    "        <td style=\"border: 1px solid #b2bec3; padding: 10px;\">Example A</td>\n",
    "        <td style=\"border: 1px solid #b2bec3; padding: 10px;\">AB<sub>2</sub>C</td>\n",
    "        <td style=\"border: 1px solid #b2bec3; padding: 10px;\">99.9</td>\n",
    "        <td style=\"border: 1px solid #b2bec3; padding: 10px;\">Sigma</td>\n",
    "        <td style=\"border: 1px solid #b2bec3; padding: 10px;\">Handle in glovebox</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td style=\"border: 1px solid #b2bec3; padding: 10px;\">Example B</td>\n",
    "        <td style=\"border: 1px solid #b2bec3; padding: 10px;\">XY<sub>3</sub></td>\n",
    "        <td style=\"border: 1px solid #b2bec3; padding: 10px;\">98.5</td>\n",
    "        <td style=\"border: 1px solid #b2bec3; padding: 10px;\">Alfa</td>\n",
    "        <td style=\"border: 1px solid #b2bec3; padding: 10px;\">Hygroscopic</td>\n",
    "      </tr>\n",
    "    </tbody>\n",
    "  </table>\n",
    "  <div style=\"font-size: 1em; color: #636e72; margin-top: 10px;\">*Replace the above with your actual precursors.*</div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d709f78b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4b6be6b",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Segoe UI', 'Arial', sans-serif; margin-bottom: 28px;\">\n",
    "  <h2 style=\"color: #00b894; font-size: 1.7em; font-weight: 700; display: flex; align-items: center; gap: 10px;\">‚öóÔ∏è 2. Synthesis Recipe</h2>\n",
    "  <ol style=\"font-size: 1.12em; color: #222; padding-left: 20px;\">\n",
    "    <li><b>Weighing and Mixing:</b>\n",
    "      <ul>\n",
    "        <li>Accurately weigh all precursors according to stoichiometry.</li>\n",
    "        <li>Mix thoroughly using an agate mortar or ball mill.</li>\n",
    "      </ul>\n",
    "    </li>\n",
    "    <li><b>Pre-calcination:</b>\n",
    "      <ul>\n",
    "        <li>Heat the mixture at 500¬∞C for 4 hours in air.</li>\n",
    "        <li>Allow to cool to room temperature.</li>\n",
    "      </ul>\n",
    "    </li>\n",
    "    <li><b>Pelletizing:</b>\n",
    "      <ul>\n",
    "        <li>Press the powder into pellets using a hydraulic press.</li>\n",
    "      </ul>\n",
    "    </li>\n",
    "    <li><b>Final Sintering:</b>\n",
    "      <ul>\n",
    "        <li>Sinter pellets at 1200¬∞C for 12 hours under argon atmosphere.</li>\n",
    "        <li>Cool down to room temperature at a rate of 5¬∞C/min.</li>\n",
    "      </ul>\n",
    "    </li>\n",
    "  </ol>\n",
    "  <div style=\"font-size: 1em; color: #636e72; margin-top: 10px;\">*Adjust steps as needed for your specific material.*</div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff031b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "979c8efa",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Segoe UI', 'Arial', sans-serif; margin-bottom: 28px;\">\n",
    "  <h2 style=\"color: #00b894; font-size: 1.7em; font-weight: 700; display: flex; align-items: center; gap: 10px;\">üß¨ 3. Expected Structure</h2>\n",
    "  <ul style=\"font-size: 1.12em; color: #222;\">\n",
    "    <li><b>Crystal Structure:</b> Perovskite-type (space group Pm-3m)</li>\n",
    "    <li><b>Phase Purity:</b> Single phase expected</li>\n",
    "    <li><b>Characterization:</b>\n",
    "      <ul>\n",
    "        <li>X-ray diffraction (XRD)</li>\n",
    "        <li>Scanning electron microscopy (SEM)</li>\n",
    "        <li>Energy-dispersive X-ray spectroscopy (EDX)</li>\n",
    "      </ul>\n",
    "    </li>\n",
    "  </ul>\n",
    "  <div style=\"font-size: 1em; color: #636e72; margin-top: 10px;\">*Replace with actual results or expectations for your material.*</div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966d9b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackaton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

```


================================================================================
=== FILE: pytest-cache-files-5q98j3cp\CACHEDIR.TAG ===
================================================================================

```
Signature: 8a477f597d28d172789f06886806bc55
# This file is a cache directory tag created by pytest.
# For information about cache directory tags, see:
#	https://bford.info/cachedir/spec.html

```


================================================================================
=== FILE: pytest-cache-files-5q98j3cp\README.md ===
================================================================================

```markdown
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.

```


================================================================================
=== FILE: pytest-cache-files-9v9c2uav\CACHEDIR.TAG ===
================================================================================

```
Signature: 8a477f597d28d172789f06886806bc55
# This file is a cache directory tag created by pytest.
# For information about cache directory tags, see:
#	https://bford.info/cachedir/spec.html

```


================================================================================
=== FILE: pytest-cache-files-9v9c2uav\README.md ===
================================================================================

```markdown
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.

```


================================================================================
=== FILE: pytest-cache-files-be92m6jh\CACHEDIR.TAG ===
================================================================================

```
Signature: 8a477f597d28d172789f06886806bc55
# This file is a cache directory tag created by pytest.
# For information about cache directory tags, see:
#	https://bford.info/cachedir/spec.html

```


================================================================================
=== FILE: pytest-cache-files-be92m6jh\README.md ===
================================================================================

```markdown
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.

```


================================================================================
=== FILE: pytest-cache-files-ckstj4qg\CACHEDIR.TAG ===
================================================================================

```
Signature: 8a477f597d28d172789f06886806bc55
# This file is a cache directory tag created by pytest.
# For information about cache directory tags, see:
#	https://bford.info/cachedir/spec.html

```


================================================================================
=== FILE: pytest-cache-files-ckstj4qg\README.md ===
================================================================================

```markdown
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.

```


================================================================================
=== FILE: pytest-cache-files-d2kqjecr\CACHEDIR.TAG ===
================================================================================

```
Signature: 8a477f597d28d172789f06886806bc55
# This file is a cache directory tag created by pytest.
# For information about cache directory tags, see:
#	https://bford.info/cachedir/spec.html

```


================================================================================
=== FILE: pytest-cache-files-d2kqjecr\README.md ===
================================================================================

```markdown
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.

```


================================================================================
=== FILE: pytest-cache-files-q02twmza\CACHEDIR.TAG ===
================================================================================

```
Signature: 8a477f597d28d172789f06886806bc55
# This file is a cache directory tag created by pytest.
# For information about cache directory tags, see:
#	https://bford.info/cachedir/spec.html

```


================================================================================
=== FILE: pytest-cache-files-q02twmza\README.md ===
================================================================================

```markdown
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.

```


================================================================================
=== FILE: pytest-cache-files-qy_idee7\CACHEDIR.TAG ===
================================================================================

```
Signature: 8a477f597d28d172789f06886806bc55
# This file is a cache directory tag created by pytest.
# For information about cache directory tags, see:
#	https://bford.info/cachedir/spec.html

```


================================================================================
=== FILE: pytest-cache-files-qy_idee7\README.md ===
================================================================================

```markdown
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.

```


================================================================================
=== FILE: pytest-cache-files-s7elq7ls\CACHEDIR.TAG ===
================================================================================

```
Signature: 8a477f597d28d172789f06886806bc55
# This file is a cache directory tag created by pytest.
# For information about cache directory tags, see:
#	https://bford.info/cachedir/spec.html

```


================================================================================
=== FILE: pytest-cache-files-s7elq7ls\README.md ===
================================================================================

```markdown
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.

```


================================================================================
=== FILE: pytest-cache-files-sx9_8emy\CACHEDIR.TAG ===
================================================================================

```
Signature: 8a477f597d28d172789f06886806bc55
# This file is a cache directory tag created by pytest.
# For information about cache directory tags, see:
#	https://bford.info/cachedir/spec.html

```


================================================================================
=== FILE: pytest-cache-files-sx9_8emy\README.md ===
================================================================================

```markdown
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.

```


================================================================================
=== FILE: pytest-cache-files-tegjyoar\CACHEDIR.TAG ===
================================================================================

```
Signature: 8a477f597d28d172789f06886806bc55
# This file is a cache directory tag created by pytest.
# For information about cache directory tags, see:
#	https://bford.info/cachedir/spec.html

```


================================================================================
=== FILE: pytest-cache-files-tegjyoar\README.md ===
================================================================================

```markdown
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.

```


================================================================================
=== FILE: pytest-cache-files-ui9s2k53\CACHEDIR.TAG ===
================================================================================

```
Signature: 8a477f597d28d172789f06886806bc55
# This file is a cache directory tag created by pytest.
# For information about cache directory tags, see:
#	https://bford.info/cachedir/spec.html

```


================================================================================
=== FILE: pytest-cache-files-ui9s2k53\README.md ===
================================================================================

```markdown
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.

```


================================================================================
=== FILE: pytest-cache-files-ur75bldd\CACHEDIR.TAG ===
================================================================================

```
Signature: 8a477f597d28d172789f06886806bc55
# This file is a cache directory tag created by pytest.
# For information about cache directory tags, see:
#	https://bford.info/cachedir/spec.html

```


================================================================================
=== FILE: pytest-cache-files-ur75bldd\README.md ===
================================================================================

```markdown
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.

```


================================================================================
=== FILE: pytest-cache-files-vp9266e_\CACHEDIR.TAG ===
================================================================================

```
Signature: 8a477f597d28d172789f06886806bc55
# This file is a cache directory tag created by pytest.
# For information about cache directory tags, see:
#	https://bford.info/cachedir/spec.html

```


================================================================================
=== FILE: pytest-cache-files-vp9266e_\README.md ===
================================================================================

```markdown
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.

```


================================================================================
=== FILE: pytest-cache-files-y5fc802v\CACHEDIR.TAG ===
================================================================================

```
Signature: 8a477f597d28d172789f06886806bc55
# This file is a cache directory tag created by pytest.
# For information about cache directory tags, see:
#	https://bford.info/cachedir/spec.html

```


================================================================================
=== FILE: pytest-cache-files-y5fc802v\README.md ===
================================================================================

```markdown
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.

```


================================================================================
=== FILE: sky\__init__.py ===
================================================================================

```python
"""
SKY - Synthesis Knowledge Yield Agent
"""

from .core.synthesis_agent import SKYSynthesisAgent

__version__ = "1.0.0"
__all__ = ["SKYSynthesisAgent"]
```


================================================================================
=== FILE: sky\cli\main.py ===
================================================================================

```python
"""
SKY - Synthesis Knowledge Yield Agent
Main CLI entry point for materials synthesis discovery
"""

import os
import sys
import shutil
from pathlib import Path

import typer
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.markdown import Markdown
from rich import print as rprint

from .ascii_art import SKY_FULL_LOGO, get_responsive_logo
from src import ASSETS_DIR
from src.utils.assets import find_asset

app = typer.Typer(
    name="sky",
    help="SKY - Synthesis Knowledge Yield Agent for materials synthesis discovery",
    add_completion=False
)
console = Console()


def show_banner():
    """Display SKY banner"""
    terminal_width = shutil.get_terminal_size().columns
    logo = get_responsive_logo(terminal_width)
    console.print(logo, style="bold cyan")


@app.command()
def search(
    query: str = typer.Argument(..., help="Material composition (e.g., Fe2O3) or CIF file path"),
    top_n: int = typer.Option(10, "--top", "-n", help="Number of similar materials"),
    structure: bool = typer.Option(False, "--structure", "-s", help="Force structure-based search"),
    show_synthesis: bool = typer.Option(True, "--synthesis/--no-synthesis", help="Show synthesis recipes"),
    html_report: bool = typer.Option(False, "--html", "-h", help="Generate HTML report"),
    output_dir: Path = typer.Option(Path.cwd(), "--output", "-o", help="Output directory for HTML report")
):
    """
    Search for similar materials and their synthesis recipes.
    
    Examples:
        sky search Fe2O3                     # Composition search
        sky search LiFePO4 --top 5           # Top 5 similar materials
        sky search Fe2O3 --html              # Generate HTML report
        sky search /path/to/file.cif         # Structure search from CIF
        sky search LiFe.cif --html -o reports # Save HTML to reports directory
    """
    show_banner()
    
    # Detect if input is a CIF file
    is_cif = query.endswith('.cif') and Path(query).exists()
    
    if is_cif:
        console.print(f"[bold cyan]üî¨ Analyzing structure from CIF file:[/] {query}\n")
        search_type = "structure"
        material_name = Path(query).stem
    else:
        console.print(f"[bold cyan]üîç Searching for materials similar to:[/] {query}\n")
        search_type = "composition"
        material_name = query
    
    try:
        from ..core.synthesis_agent import SKYSynthesisAgent
        from ..report.html_generator import HTMLReportGenerator
        
        # Initialize agent
        console.print("[dim]Initializing SKY agent...[/]")
        session_id = f"sky_search_{Path(query).stem if is_cif else query}"
        agent = SKYSynthesisAgent(session_id=session_id)
        
        # Run discovery
        console.print(f"[dim]Discovering synthesis methods using {search_type} similarity...[/]")
        result = agent.discover_synthesis_sync(query)
        
        # Display results
        console.print("\n[bold green]üìä Results:[/]\n")
        console.print(Markdown(result))
        
        # Generate HTML report if requested
        if html_report:
            console.print("\n[bold cyan]üìÑ Generating HTML report...[/]")
            generator = HTMLReportGenerator()
            report_data = generator.parse_agent_output(result)
            
            # Ensure material formula is set
            if not report_data.material_formula:
                report_data.material_formula = material_name
                report_data.material_formula_html = generator._formula_to_html(material_name)
            
            # Create output directory if needed
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # Generate filename
            import re
            safe_name = re.sub(r'[^\w\s-]', '', material_name)
            output_path = output_dir / f"{safe_name}_synthesis_report.html"
            
            # Save report
            saved_path = generator.save_report(report_data, output_path)
            console.print(f"[bold green]‚úÖ HTML report saved:[/] {saved_path}")
            
            # Optionally open in browser
            if typer.confirm("Open report in browser?", default=True):
                import webbrowser
                webbrowser.open(f"file://{saved_path.absolute()}")
        
    except Exception as e:
        console.print(f"[bold red]‚ùå Error:[/] {e}")
        raise typer.Exit(1)


@app.command()
def chat():
    """
    Interactive chat mode for synthesis discovery.
    """
    show_banner()
    console.print("[bold cyan]üí¨ SKY Interactive Chat Mode[/]")
    console.print("[dim]Type 'quit' or 'exit' to leave[/]\n")
    
    try:
        from ..core.synthesis_agent import SKYSynthesisAgent
        
        # Initialize agent with session
        agent = SKYSynthesisAgent(session_id="sky_chat_session")
        console.print("[green]‚úÖ SKY agent ready![/]\n")
        
        while True:
            # Get user input
            query = typer.prompt("\n[bold]You[/]", prompt_suffix=": ")
            
            if query.lower() in ["quit", "exit", "bye"]:
                console.print("\n[cyan]üëã Goodbye! Thank you for using SKY.[/]")
                break
            
            # Process query
            console.print("\n[dim]SKY is thinking...[/]")
            try:
                result = agent.discover_synthesis_sync(query)
                console.print(f"\n[bold cyan]SKY:[/]\n")
                console.print(Markdown(result))
            except Exception as e:
                console.print(f"[red]Error processing query: {e}[/]")
                
    except KeyboardInterrupt:
        console.print("\n\n[cyan]üëã Chat interrupted. Goodbye![/]")
    except Exception as e:
        console.print(f"[bold red]‚ùå Error initializing chat:[/] {e}")
        raise typer.Exit(1)


@app.command()
def setup():
    """
    Check environment setup and dependencies.
    """
    show_banner()
    console.print("[bold]‚öôÔ∏è SKY Environment Check[/]\n")
    
    # Create status table
    table = Table(title="Configuration Status")
    table.add_column("Component", style="cyan")
    table.add_column("Status", style="green")
    table.add_column("Details")
    
    # Check API keys
    openai_key = os.getenv("OPENAI_MDG_API_KEY") or os.getenv("OPENAI_API_KEY")
    mp_key = os.getenv("MP_API_KEY")
    
    table.add_row(
        "OpenAI API Key",
        "‚úÖ Set" if openai_key else "‚ùå Missing",
        "Required for AI synthesis analysis"
    )
    
    table.add_row(
        "Materials Project API Key",
        "‚úÖ Set" if mp_key else "‚ö†Ô∏è Optional",
        "Enables live materials data"
    )
    
    # Check dependencies
    deps = [
        ("pymatgen", "Materials analysis"),
        ("openai_agents", "Agent framework"),
        ("monty", "Data serialization"),
        ("h5py", "Embedding storage"),
        ("mace_torch", "Structure embeddings")
    ]
    
    for module_name, description in deps:
        try:
            __import__(module_name.replace("-", "_"))
            table.add_row(module_name, "‚úÖ Installed", description)
        except ImportError:
            table.add_row(module_name, "‚ùå Missing", description)
    
    # Check data files
    synthesis_file = find_asset(
        preferred_names=["mp_synthesis_recipes.json.gz"],
        globs=["*synthesis*recipes*.json*"],
        base=ASSETS_DIR,
    )
    embedding_file = find_asset(
        preferred_names=["mp_dataset_composition_magpie.h5"],
        globs=["*composition*.h5"],
        base=ASSETS_DIR / "embedding",
    )
    structure_embedding_file = find_asset(
        preferred_names=["mp_dataset_structure_mace.h5"],
        globs=["*structure*.h5"],
        base=ASSETS_DIR / "embedding",
    )
    
    table.add_row(
        "Synthesis Recipes",
        "Found" if synthesis_file and synthesis_file.exists() else "Missing",
        f"{synthesis_file.stat().st_size / 1024 / 1024:.1f} MB"
        if synthesis_file and synthesis_file.exists()
        else "Required for synthesis data"
    )
    
    table.add_row(
        "Composition Embeddings",
        "Found" if embedding_file and embedding_file.exists() else "Missing",
        f"{embedding_file.stat().st_size / 1024 / 1024:.1f} MB"
        if embedding_file and embedding_file.exists()
        else "Required for similarity search"
    )
    
    table.add_row(
        "Structure Embeddings",
        "Found"
        if structure_embedding_file and structure_embedding_file.exists()
        else "Missing",
        f"{structure_embedding_file.stat().st_size / 1024 / 1024:.1f} MB"
        if structure_embedding_file and structure_embedding_file.exists()
        else "Required for structure similarity search"
    )
    
    console.print(table)
    
    # Recommendations
    console.print("\n[bold]üìù Recommendations:[/]")
    if not openai_key:
        console.print("  1. Set OPENAI_MDG_API_KEY environment variable")
    if not mp_key:
        console.print("  2. Set MP_API_KEY for enhanced materials data")
    
    console.print("\n[green]‚úÖ SKY is ready for synthesis discovery![/]")


@app.command()
def demo():
    """
    Show feature demonstration and examples.
    """
    show_banner()
    
    demo_text = """
# SKY - Synthesis Knowledge Yield Agent

## üî¨ Core Capabilities:
- **Composition Search**: Find materials similar to Fe2O3, LiCoO2, etc.
- **Synthesis Discovery**: Retrieve synthesis recipes from database
- **Parameter Analysis**: Extract temperature, time, atmosphere conditions
- **Smart Recommendations**: AI-powered synthesis route suggestions
- **Interactive Chat**: Multi-turn conversations with context

## üß™ Example Workflows:

### 1. Basic Synthesis Search
```bash
sky search Fe2O3
```
‚Üí Finds similar iron oxides (Fe3O4, FeO, Œ±-Fe2O3)
‚Üí Retrieves synthesis recipes for each
‚Üí Analyzes synthesis parameters
‚Üí Recommends optimal synthesis route

### 2. Battery Material Discovery
```bash
sky search LiFePO4 --top 5
```
‚Üí Identifies similar cathode materials
‚Üí Compares synthesis methods
‚Üí Highlights critical parameters
‚Üí Suggests alternatives based on properties

### 3. Interactive Exploration
```bash
sky chat
You: I need to synthesize BiFeO3
SKY: [Provides synthesis routes, conditions, precursors]
You: What temperature is best for phase purity?
SKY: [Analyzes temperature effects on BiFeO3 formation]
```

## üìä Data Sources:
- **Materials Project**: Live API for properties
- **Synthesis Database**: 1M+ recipes from literature
- **Embedding Search**: Fast similarity matching
- **AI Analysis**: GPT-powered insights

## üöÄ Ready to accelerate your materials synthesis research!
    """
    
    console.print(Markdown(demo_text))


@app.command()
def version():
    """
    Show SKY version information.
    """
    console.print("[bold cyan]SKY - Synthesis Knowledge Yield Agent[/]")
    console.print("Version: 1.0.0")
    console.print("Model: o3 (configurable)")
    console.print("Copyright 2025 - Materials Discovery Team")


def main():
    """Main entry point for SKY CLI"""
    try:
        app()
    except KeyboardInterrupt:
        console.print("\n[cyan]üëã Operation cancelled.[/]")
        raise typer.Exit(0)
    except Exception as e:
        console.print(f"\n[bold red]Unexpected error:[/] {e}")
        raise typer.Exit(1)


if __name__ == "__main__":
    main()

```


================================================================================
=== FILE: sky\cli\__init__.py ===
================================================================================

```python
"""
SKY CLI components
"""

from .main import app, main

__all__ = ["app", "main"]
```


================================================================================
=== FILE: sky\core\synthesis_agent.py ===
================================================================================

```python
"""
SKY Synthesis Agent - Core implementation for materials synthesis discovery
"""

import json
import os
import re
from typing import Any, Dict, List, Optional
from pathlib import Path

from monty.serialization import loadfn
from agents import Agent, Runner, SQLiteSession, function_tool
from pymatgen.core import Composition, Structure

from src import ASSETS_DIR
from src.embedding import InputType
from src.search_api import SearchAPI
from src.agent import SynthesisAgent as CoreSynthesisAgent
from src.schema import Neighbor
from src.recursive_synthesis import RecursiveSynthesisSearch
from src.utils.assets import find_asset
from sky.report.html_generator import HTMLReportGenerator, SynthesisReportData

DEFAULT_MODEL = "o3"

SYNTHESIS_AGENT_PROMPT = """
You are SKY (Synthesis Knowledge Yield), an expert materials synthesis specialist focused on helping researchers discover and understand synthesis recipes for materials.

Your expertise includes:
1. Chemical synthesis methods (solid-state, sol-gel, hydrothermal, CVD, etc.)
2. Reaction conditions (temperature, pressure, atmosphere, time)
3. Precursor selection and stoichiometry
4. Crystal growth techniques
5. Materials characterization methods
6. Safety considerations and best practices

When analyzing synthesis:
- Focus on practical, reproducible methods
- Consider multiple synthesis routes when available
- Highlight critical parameters for successful synthesis
- Note safety hazards and required equipment
- Suggest alternatives when appropriate
- Compare methods based on yield, purity, and scalability

Be detailed about synthesis procedures but concise in explanations.
Format responses with clear sections and use scientific terminology appropriately.
"""


@function_tool
def read_cif_file(file_path: str) -> str:
    """
    Read and analyze a crystal structure from a CIF file.
    
    Args:
        file_path: Path to the CIF file
    
    Returns:
        JSON string with structure information
    """
    try:
        from pymatgen.core import Structure
        
        # Read CIF file
        structure = Structure.from_file(file_path)
        
        analysis = {
            "file_path": file_path,
            "formula": structure.composition.formula,
            "reduced_formula": structure.composition.reduced_formula,
            "volume": structure.volume,
            "density": structure.density,
            "num_sites": structure.num_sites,
            "lattice": {
                "a": structure.lattice.a,
                "b": structure.lattice.b,
                "c": structure.lattice.c,
                "alpha": structure.lattice.alpha,
                "beta": structure.lattice.beta,
                "gamma": structure.lattice.gamma,
                "volume": structure.lattice.volume,
            },
            "elements": [str(el) for el in structure.composition.elements],
        }
        
        return json.dumps(analysis, indent=2, default=str)
        
    except Exception as e:
        return json.dumps({
            "error": str(e),
            "file_path": file_path
        }, indent=2)


@function_tool
def search_similar_materials_advanced(
    query: str = None, 
    cif_file: str = None,
    input_type: str = "auto",
    top_n: int = 10
) -> str:
    """
    Advanced search for similar materials using composition or structure.
    
    Args:
        query: Composition formula (e.g., "Fe2O3") or None
        cif_file: Path to CIF file for structure search or None
        input_type: "composition", "structure", or "auto" (default)
        top_n: Number of similar materials to find (default 10)
    
    Returns:
        JSON string with similar materials and their properties
    """
    try:
        # Initialize core synthesis agent
        core_agent = CoreSynthesisAgent()
        
        # Determine input type and search
        if cif_file:
            # Structure-based search from CIF file
            structure = Structure.from_file(cif_file)
            neighbors = core_agent.find_similar_materials_by_structure(
                structure, n_neighbors=top_n
            )
            search_type = "structure"
            search_query = f"CIF file: {cif_file}"
        elif query:
            # Composition-based search
            neighbors = core_agent.find_similar_materials_by_composition(
                query, n_neighbors=top_n
            )
            search_type = "composition"
            search_query = query
        else:
            return json.dumps({
                "error": "Either query or cif_file must be provided"
            }, indent=2)
        
        # Convert Neighbor objects to dict
        results = {
            "search_type": search_type,
            "query": search_query,
            "num_results": len(neighbors),
            "similar_materials": [
                {
                    "rank": n.neighbor_index + 1,
                    "material_id": n.material_id,
                    "formula": n.formula,
                    "distance": n.distance,
                }
                for n in neighbors
            ]
        }
        
        return json.dumps(results, indent=2, default=str)
        
    except Exception as e:
        return json.dumps({
            "error": str(e),
            "query": query,
            "cif_file": cif_file
        }, indent=2)


@function_tool
def get_material_properties(material_ids: List[str]) -> str:
    """
    Fetch detailed properties for Materials Project materials.
    
    Args:
        material_ids: List of MP material IDs (e.g., ["mp-149", "mp-2834"])
    
    Returns:
        JSON string with material properties
    """
    try:
        # Import the MP client from hackathon code (we'll adapt it)
        import sys

        from mp_api.client import MPRester
        
        mp_key = os.getenv("MP_API_KEY")
        if not mp_key:
            return json.dumps({
                "error": "MP_API_KEY not found in environment"
            }, indent=2)
        
        results = []
        with MPRester(mp_key) as mpr:
            docs = mpr.materials.summary.search(material_ids=material_ids)
            
            for doc in docs:
                material_dict = {
                    "material_id": doc.material_id,
                    "formula_pretty": doc.formula_pretty,
                    "band_gap": doc.band_gap,
                    "density": doc.density,
                    "formation_energy_per_atom": doc.formation_energy_per_atom,
                    "energy_above_hull": doc.energy_above_hull,
                    "volume": doc.volume if hasattr(doc, 'volume') else None,
                    "mp_url": f"https://materialsproject.org/materials/{doc.material_id}"
                }
                results.append(material_dict)
        
        return json.dumps(results, indent=2, default=str)
        
    except Exception as e:
        return json.dumps({
            "error": str(e),
            "material_ids": material_ids
        }, indent=2)


@function_tool
def get_synthesis_recipes(target_formula: str, similar_formulas: Optional[List[str]] = None) -> str:
    """
    Retrieve synthesis recipes for target material and similar materials.
    
    Args:
        target_formula: Primary formula to find synthesis for (e.g., "Fe2O3")
        similar_formulas: Optional list of similar formulas to check
    
    Returns:
        JSON string with synthesis recipes and methods
    """
    try:
        # Load synthesis recipes from compressed JSON
        recipes_file = find_asset(
            preferred_names=["mp_synthesis_recipes.json.gz"],
            globs=["*synthesis*recipes*.json*"],
            base=ASSETS_DIR,
        )
        
        if not recipes_file or not recipes_file.exists():
            # Try Materials Project API as fallback
            mp_key = os.getenv("MP_API_KEY")
            if mp_key:
                from mp_api.client import MPRester
                with MPRester(mp_key) as mpr:
                    recipes = mpr.materials.synthesis.search(target_formula=target_formula)
                    
                    results = {
                        "target_formula": target_formula,
                        "recipes_found": len(recipes),
                        "recipes": []
                    }
                    
                    for recipe in recipes[:5]:  # Limit to 5 recipes
                        recipe_dict = {
                            "doi": recipe.doi if hasattr(recipe, 'doi') else None,
                            "paragraph_string": recipe.paragraph_string if hasattr(recipe, 'paragraph_string') else None,
                            "synthesis_type": recipe.synthesis_type if hasattr(recipe, 'synthesis_type') else None,
                            "reaction_string": recipe.reaction_string if hasattr(recipe, 'reaction_string') else None,
                            "target": recipe.target_string if hasattr(recipe, 'target_string') else None,
                        }
                        results["recipes"].append(recipe_dict)
                    
                    return json.dumps(results, indent=2, default=str)
            else:
                return json.dumps({
                    "error": "Synthesis recipes file not found and MP_API_KEY not set"
                }, indent=2)
        
        # Load compressed synthesis data
        all_recipes = loadfn(recipes_file)
        
        # Search for recipes matching target formula
        target_comp = Composition(target_formula)
        matched_recipes = []
        
        # Check both exact and reduced formula matches
        for recipe in all_recipes:
            if 'target_formula' in recipe:
                try:
                    recipe_comp = Composition(recipe['target_formula'])
                    if (recipe_comp.reduced_formula == target_comp.reduced_formula or 
                        recipe_comp.formula == target_comp.formula):
                        matched_recipes.append(recipe)
                except:
                    continue
        
        # Also check similar formulas if provided
        similar_recipes = []
        if similar_formulas:
            for formula in similar_formulas:
                try:
                    sim_comp = Composition(formula)
                    for recipe in all_recipes:
                        if 'target_formula' in recipe:
                            try:
                                recipe_comp = Composition(recipe['target_formula'])
                                if recipe_comp.reduced_formula == sim_comp.reduced_formula:
                                    similar_recipes.append({
                                        "formula": formula,
                                        "recipe": recipe
                                    })
                            except:
                                continue
                except:
                    continue
        
        results = {
            "target_formula": target_formula,
            "exact_matches": len(matched_recipes),
            "recipes": matched_recipes[:5],  # Limit to 5 recipes
            "similar_materials_recipes": similar_recipes[:3]  # Limit to 3 similar
        }
        
        return json.dumps(results, indent=2, default=str)
        
    except Exception as e:
        return json.dumps({
            "error": str(e),
            "target_formula": target_formula
        }, indent=2)


@function_tool
def analyze_synthesis_parameters(synthesis_text: str) -> str:
    """
    Extract and analyze key synthesis parameters from a synthesis description.
    
    Args:
        synthesis_text: Text description of synthesis procedure
    
    Returns:
        JSON string with extracted parameters and analysis
    """
    import re
    
    try:
        # Extract temperatures
        temp_patterns = [
            r'(\d+)\s*¬∞C',
            r'(\d+)\s*K',
            r'(\d+)\s*degrees?\s*C',
            r'(\d+)\s*celsius'
        ]
        temperatures = []
        for pattern in temp_patterns:
            temps = re.findall(pattern, synthesis_text, re.IGNORECASE)
            temperatures.extend(temps)
        
        # Extract times
        time_patterns = [
            r'(\d+)\s*hours?',
            r'(\d+)\s*h\b',
            r'(\d+)\s*minutes?',
            r'(\d+)\s*min\b',
            r'(\d+)\s*days?'
        ]
        times = []
        for pattern in time_patterns:
            time_vals = re.findall(pattern, synthesis_text, re.IGNORECASE)
            times.extend(time_vals)
        
        # Identify synthesis method keywords
        methods = {
            "solid_state": ["solid state", "ceramic", "calcination", "sintering"],
            "sol_gel": ["sol-gel", "sol gel", "gelation", "xerogel"],
            "hydrothermal": ["hydrothermal", "solvothermal", "autoclave"],
            "precipitation": ["precipitation", "coprecipitation", "co-precipitation"],
            "cvd": ["CVD", "chemical vapor", "vapor deposition"],
            "combustion": ["combustion", "self-propagating", "SHS"],
            "flux": ["flux", "molten salt", "flux growth"]
        }
        
        detected_methods = []
        for method, keywords in methods.items():
            for keyword in keywords:
                if keyword.lower() in synthesis_text.lower():
                    detected_methods.append(method)
                    break
        
        # Extract atmosphere conditions
        atmospheres = []
        atm_keywords = ["air", "argon", "nitrogen", "N2", "Ar", "oxygen", "O2", "vacuum", "inert"]
        for keyword in atm_keywords:
            if keyword.lower() in synthesis_text.lower():
                atmospheres.append(keyword)
        
        analysis = {
            "temperatures_C": list(set(temperatures)),
            "time_durations": list(set(times)),
            "synthesis_methods": list(set(detected_methods)),
            "atmosphere": list(set(atmospheres)),
            "has_heating": bool(temperatures),
            "text_length": len(synthesis_text)
        }
        
        return json.dumps(analysis, indent=2)
        
    except Exception as e:
        return json.dumps({
            "error": str(e),
            "text": synthesis_text[:100] + "..." if len(synthesis_text) > 100 else synthesis_text
        }, indent=2)


@function_tool
def generate_synthesis_html_report(
    synthesis_output: str,
    material_formula: str,
    output_filename: Optional[str] = None
) -> str:
    """
    Generate a professional HTML report from synthesis analysis output.
    
    Args:
        synthesis_output: The formatted synthesis analysis text output
        material_formula: The target material formula (e.g., "NaFe2O4")
        output_filename: Optional filename for the HTML report (defaults to formula-based name)
    
    Returns:
        Path to the generated HTML report file
    """
    try:
        generator = HTMLReportGenerator()
        
        # Parse the synthesis output
        report_data = generator.parse_agent_output(synthesis_output)
        
        # Ensure material formula is set
        if not report_data.material_formula:
            report_data.material_formula = material_formula
            report_data.material_formula_html = generator._formula_to_html(material_formula)
        
        # Generate output path
        if output_filename:
            output_path = Path(output_filename)
        else:
            safe_name = re.sub(r'[^\w\s-]', '', material_formula)
            output_path = Path(f"{safe_name}_synthesis_report.html")
        
        # Generate and save the report
        saved_path = generator.save_report(report_data, output_path)
        
        return json.dumps({
            "status": "success",
            "report_path": str(saved_path.absolute()),
            "material": material_formula,
            "message": f"HTML report generated successfully: {saved_path.name}"
        }, indent=2)
        
    except Exception as e:
        return json.dumps({
            "error": str(e),
            "material": material_formula,
            "message": "Failed to generate HTML report"
        }, indent=2)


@function_tool
def recursive_synthesis_search(
    target_formula: str,
    max_depth: int = 3,
    min_confidence: float = 0.7,
    n_initial_neighbors: int = 30
) -> str:
    """
    Perform recursive best-guess search for synthesis recipes.
    
    This advanced algorithm recursively explores similar materials when direct recipes
    are not available, using confidence scores to guide the search.
    
    Args:
        target_formula: Target material composition (e.g., "LiFe2O4")
        max_depth: Maximum recursion depth (default 3)
        min_confidence: Minimum confidence threshold (default 0.7)
        n_initial_neighbors: Initial neighbors to explore (default 30)
    
    Returns:
        JSON string with recursive search results and best guess synthesis
    """
    try:
        # Initialize recursive search
        recursive_search = RecursiveSynthesisSearch(
            synthesis_agent=CoreSynthesisAgent(),
            max_depth=max_depth,
            min_confidence=min_confidence,
            verbose=True  # Enable progress printing
        )
        
        # Perform recursive search
        results = recursive_search.search(
            target_formula=target_formula,
            n_initial_neighbors=n_initial_neighbors
        )
        
        # Enhance results with summary
        if results["status"] == "success":
            results["summary"] = f"Found {results['unique_materials_with_recipes']} materials with recipes through recursive search of {results['visited_materials']} materials"
        
        return json.dumps(results, indent=2, default=str)
        
    except Exception as e:
        return json.dumps({
            "error": str(e),
            "target_formula": target_formula,
            "message": "Recursive search failed"
        }, indent=2)


class SKYSynthesisAgent:
    """
    SKY - Synthesis Knowledge Yield Agent
    Orchestrates materials synthesis discovery and recipe recommendation.
    """
    
    def __init__(self, session_id: str = None, model: str = DEFAULT_MODEL):
        self.model = model
        self.session = SQLiteSession(session_id) if session_id else None
        
        # Set OpenAI API key from environment
        openai_key = os.getenv("OPENAI_MDG_API_KEY")
        if openai_key:
            os.environ["OPENAI_API_KEY"] = openai_key
        
        # Create agent with synthesis tools
        self.agent = Agent(
            name="SKY_SynthesisExpert",
            instructions=SYNTHESIS_AGENT_PROMPT,
            model=self.model,
            tools=[
                read_cif_file,
                search_similar_materials_advanced,
                get_material_properties,
                get_synthesis_recipes,
                analyze_synthesis_parameters,
                recursive_synthesis_search,
                generate_synthesis_html_report
            ]
        )
    
    def discover_synthesis_sync(self, query: str, cif_file: str = None) -> str:
        """
        Run synthesis discovery synchronously.
        
        Args:
            query: Material formula, CIF file path, or synthesis query
            cif_file: Optional explicit CIF file path
            
        Returns:
            Synthesis recommendations and procedures
        """
        # Check if query is a CIF file path
        is_cif = cif_file or (query and query.endswith('.cif') and Path(query).exists())
        
        if is_cif:
            cif_path = cif_file or query
            prompt = f"""
            Handle this structure-based synthesis discovery from CIF file: "{cif_path}"
            
            WORKFLOW:
            1. Use read_cif_file to analyze the crystal structure
            2. Use search_similar_materials_advanced with cif_file parameter to find 10 similar materials by structure
            3. Use get_material_properties to understand the materials' characteristics
            4. Use get_synthesis_recipes for both the target composition and top 3 similar materials
            5. If recipes found, use analyze_synthesis_parameters to extract key conditions
            6. Synthesize findings into actionable recommendations
            """
        else:
            prompt = f"""
            Handle this synthesis discovery query: "{query}"
            
            WORKFLOW:
            1. First, identify if this is a composition formula (e.g., Fe2O3) or general query
            2. Use search_similar_materials_advanced to find 10 similar materials by composition
            3. Use get_material_properties to understand the materials' characteristics
            4. Use get_synthesis_recipes for the target material
            5. IF NO DIRECT RECIPES FOUND:
               - Use recursive_synthesis_search to perform deep search across neighbor materials
               - This will explore neighbors-of-neighbors to find adaptable recipes
            6. If recipes found, use analyze_synthesis_parameters to extract key conditions
            7. Synthesize findings into actionable recommendations
        
        RESPONSE FORMAT:
        üìä Target Material Analysis
        - Formula and composition
        - Key properties (if available)
        
        üî¨ Synthesis Methods Found
        - Primary synthesis routes
        - Temperature/time conditions
        - Atmosphere requirements
        
        üß™ Recommended Procedure
        - Step-by-step synthesis
        - Critical parameters
        - Safety considerations
        
        üìù Alternative Routes
        - Similar materials' methods
        - Pros/cons of each approach
        
        Focus on practical, reproducible synthesis procedures.
        
        IMPORTANT: After completing the synthesis analysis, ALWAYS generate an HTML report
        using generate_synthesis_html_report with your complete analysis output.
        """
        
        result = Runner.run_sync(self.agent, input=prompt, session=self.session)
        return result.final_output
    
    async def discover_synthesis(self, query: str) -> str:
        """
        Run synthesis discovery asynchronously.
        """
        prompt = f"""
        Discover synthesis methods for: "{query}"
        
        Execute complete synthesis discovery workflow:
        1. Search for similar materials
        2. Retrieve material properties
        3. Find synthesis recipes
        4. Analyze synthesis parameters
        5. Provide comprehensive synthesis recommendations
        
        Be thorough and practical in your recommendations.
        """
        
        result = await Runner.run(self.agent, input=prompt, session=self.session)
        return result.final_output

```


================================================================================
=== FILE: sky\core\__init__.py ===
================================================================================

```python
"""
SKY Core components
"""

from .synthesis_agent import SKYSynthesisAgent

__all__ = ["SKYSynthesisAgent"]
```


================================================================================
=== FILE: sky\report\html_generator.py ===
================================================================================

```python
"""HTML Report Generator for SKY Synthesis Agent

Generates professional HTML reports from synthesis search results.
"""

import re
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field


@dataclass
class SynthesisReportData:
    """Data structure for synthesis report generation"""
    material_formula: str
    material_formula_html: str = ""
    analysis: Dict[str, Any] = field(default_factory=dict)
    synthesis_methods: List[Dict[str, Any]] = field(default_factory=list)
    recommended_procedure: Dict[str, Any] = field(default_factory=dict)
    critical_parameters: List[str] = field(default_factory=list)
    safety_considerations: List[str] = field(default_factory=list)
    alternative_routes: List[Dict[str, Any]] = field(default_factory=list)
    related_materials: List[str] = field(default_factory=list)
    confidence_score: float = 0.0
    search_depth: int = 0
    recipes_found: int = 0
    generation_date: str = ""
    raw_output: str = ""


class HTMLReportGenerator:
    """Generates HTML synthesis reports from agent output"""
    
    def __init__(self, template_path: Optional[Path] = None):
        """Initialize with optional custom template"""
        self.template_path = template_path or Path(__file__).parent / "template.html"
        
    def parse_agent_output(self, raw_output: str) -> SynthesisReportData:
        """Parse raw SKY agent output into structured report data"""
        data = SynthesisReportData(
            material_formula="",
            generation_date=datetime.now().strftime("%d %b %Y"),
            raw_output=raw_output
        )
        
        # Extract material formula - look for various patterns
        formula_patterns = [
            r"Formula:\s*([A-Za-z0-9‚ÇÄ-‚Çâ()]+)",  # Unicode subscripts
            r"Formula:\s*([A-Z][a-zA-Z0-9()]+(?:\s*[A-Z][a-zA-Z0-9()]+)*)",
            r"Target Material Analysis.*?([A-Z][a-z]?\d*[A-Z][a-z]?\d*[A-Z]?[a-z]?\d*)",
            r"for\s+([A-Z][a-z]?\d*[A-Z][a-z]?\d*[A-Z]?[a-z]?\d*)",
        ]
        
        for pattern in formula_patterns:
            formula_match = re.search(pattern, raw_output)
            if formula_match:
                formula = formula_match.group(1).strip()
                # Convert unicode subscripts to normal numbers
                formula = formula.replace('‚ÇÄ', '0').replace('‚ÇÅ', '1').replace('‚ÇÇ', '2')
                formula = formula.replace('‚ÇÉ', '3').replace('‚ÇÑ', '4').replace('‚ÇÖ', '5')
                formula = formula.replace('‚ÇÜ', '6').replace('‚Çá', '7').replace('‚Çà', '8').replace('‚Çâ', '9')
                data.material_formula = formula
                data.material_formula_html = self._formula_to_html(formula)
                break
        
        # Extract key properties from bullet points in analysis section
        analysis_section = re.search(r"Target Material Analysis(.*?)(?:üî¨|Synthesis|$)", raw_output, re.DOTALL)
        if analysis_section:
            analysis_text = analysis_section.group(1)
            
            # Extract structure/prototype info
            structure_match = re.search(r"Prototype/Structure:\s*([^‚Ä¢\n]+(?:\n[^‚Ä¢\n]+)*)", analysis_text)
            if structure_match:
                data.analysis["structure"] = structure_match.group(1).strip()
            
            # Extract thermodynamic stability
            stability_match = re.search(r"Thermodynamic stability:\s*([^‚Ä¢\n]+(?:\n[^‚Ä¢\n]+)*)", analysis_text)
            if stability_match:
                data.analysis["thermodynamic_stability"] = stability_match.group(1).strip()
            
            # Look for density mentions
            density_match = re.search(r"density[^0-9]*([0-9.,‚Äì\-\s]+g[^;]*)", analysis_text, re.IGNORECASE)
            if density_match:
                data.analysis["density"] = density_match.group(1).strip()
            
            # Look for band gap
            bandgap_match = re.search(r"(\d+[‚Äì\-]?\d*\.?\d*\s*eV[^)]*)", analysis_text)
            if bandgap_match:
                data.analysis["band_gap"] = bandgap_match.group(1).strip()
        
        # Extract synthesis methods - improved parsing
        methods = []
        
        # Look for synthesis methods section - broader search
        method_section = re.search(r"(üî¨.*?)(?:üß™|üìù|Critical|Safety|Alternative|$)", raw_output, re.DOTALL)
        if method_section:
            method_text = method_section.group(1)
            
            # Find numbered methods - use the pattern that worked in debug
            pattern = r"(\d+)\s+([^:\n]+):\s*\n((?:[^0-9][^\n]*\n?)+?)(?=\d+\s+\w+|üß™|üìù|$)"
            method_blocks = re.findall(pattern, method_text, re.MULTILINE | re.DOTALL)
            
            for num, name, content in method_blocks:
                method = {
                    "name": name.strip().rstrip(':'),
                    "details": []
                }
                
                # Extract bullet points - look for lines starting with dash/bullet
                lines = content.split('\n')
                current_bullet = ""
                
                for line in lines:
                    line = line.strip()
                    if line.startswith(('‚Äì', '‚Ä¢', '¬∑', '-')) and len(line) > 2:
                        # Save previous bullet if exists
                        if current_bullet:
                            method["details"].append(current_bullet.strip())
                        # Start new bullet
                        current_bullet = line[1:].strip()  # Remove bullet marker
                    elif line and current_bullet:
                        # Continue previous bullet
                        current_bullet += " " + line
                
                # Add the last bullet
                if current_bullet:
                    method["details"].append(current_bullet.strip())
                
                if method["details"]:  # Only add if we found details
                    methods.append(method)
        
        data.synthesis_methods = methods
        
        # Extract recommended procedure
        if "Recommended Procedure" in raw_output:
            proc_match = re.search(r"Recommended Procedure[^:]*:(.*?)(?:Critical parameters|Safety|Alternative|$)", raw_output, re.DOTALL)
            if proc_match:
                proc_text = proc_match.group(1)
                steps = re.findall(r"(\d+)\s*([^0-9]+?)(?=\d+\s+\w+|$)", proc_text)
                data.recommended_procedure = {
                    "steps": [{"number": num, "description": desc.strip()} for num, desc in steps]
                }
        
        # Extract critical parameters - improved parsing
        if "Critical parameters" in raw_output or "critical" in raw_output.lower():
            crit_match = re.search(r"Critical parameters[^:]*:(.*?)(?:Yield|Safety|üìù|Alternative|$)", raw_output, re.DOTALL | re.IGNORECASE)
            if crit_match:
                crit_text = crit_match.group(1)
                # Extract lines starting with bullet or dash
                bullets = re.findall(r"[‚Ä¢¬∑‚Äì-]\s*([^\n‚Ä¢¬∑‚Äì]+)", crit_text)
                data.critical_parameters = [b.strip() for b in bullets if b.strip()]
        
        # Extract safety considerations - improved parsing  
        if "Safety" in raw_output:
            safety_match = re.search(r"Safety[^:]*:(.*?)(?:üìù|Alternative|Pros|Selection|$)", raw_output, re.DOTALL | re.IGNORECASE)
            if safety_match:
                safety_text = safety_match.group(1)
                bullets = re.findall(r"[‚Ä¢¬∑‚Äì-]\s*([^\n‚Ä¢¬∑‚Äì]+)", safety_text)
                data.safety_considerations = [b.strip() for b in bullets if b.strip()]
        
        # Extract alternative routes
        if "Alternative" in raw_output:
            alt_match = re.search(r"Alternative[^:]*:(.*?)(?:Selection|Pros|By adhering|$)", raw_output, re.DOTALL)
            if alt_match:
                alt_text = alt_match.group(1)
                alt_methods = re.findall(r"(\d+)\s+([\w\s\-‚Äì]+)\s*\n\s*Pros:(.*?)\s*Cons:(.*?)(?=\d+\s+\w+|$)", alt_text, re.DOTALL)
                for num, name, pros, cons in alt_methods:
                    data.alternative_routes.append({
                        "name": name.strip(),
                        "pros": pros.strip(),
                        "cons": cons.strip()
                    })
        
        # Extract related materials - look for specific mentions
        related = []
        
        # Look for explicit material mentions in the analysis
        material_patterns = [
            r"(Na[A-Za-z]*[0-9]*O[0-9]*)",  # Sodium compounds
            r"(Li[A-Za-z]*[0-9]*O[0-9]*)",   # Lithium compounds
            r"([A-Z][a-z]?Fe[0-9]*O[0-9]*)", # Iron oxides
            r"(Fe[0-9]*O[0-9]*)",           # Simple iron oxides
        ]
        
        for pattern in material_patterns:
            matches = re.findall(pattern, raw_output)
            related.extend(matches)
        
        # Look for materials specifically mentioned as "closest" or "similar"
        closest_match = re.search(r"closest[^:]*include\s*([^.]+)", raw_output, re.IGNORECASE)
        if closest_match:
            closest_materials = re.findall(r"([A-Z][a-zA-Z0-9‚ÇÄ-‚Çâ]*)", closest_match.group(1))
            related.extend(closest_materials)
        
        # Clean up and convert unicode subscripts
        cleaned_related = []
        for material in set(related):  # Remove duplicates
            if len(material) > 2:  # Filter out single letters
                # Convert unicode subscripts
                clean_mat = material.replace('‚ÇÄ', '0').replace('‚ÇÅ', '1').replace('‚ÇÇ', '2')
                clean_mat = clean_mat.replace('‚ÇÉ', '3').replace('‚ÇÑ', '4').replace('‚ÇÖ', '5')
                clean_mat = clean_mat.replace('‚ÇÜ', '6').replace('‚Çá', '7').replace('‚Çà', '8').replace('‚Çâ', '9')
                cleaned_related.append(clean_mat)
        
        data.related_materials = list(set(cleaned_related))[:8]  # Unique, limit to 8
        
        return data
    
    def _formula_to_html(self, formula: str) -> str:
        """Convert chemical formula to HTML with subscripts"""
        # Handle parentheses first
        formula = re.sub(r'\(([^)]+)\)', r'(\1)', formula)
        # Convert numbers to subscripts
        formula = re.sub(r'(\d+)', r'<sub>\1</sub>', formula)
        # Handle special cases like charges
        formula = re.sub(r'\^([\+\-]?\d*)', r'<sup>\1</sup>', formula)
        return formula
    
    def generate_html(self, data: SynthesisReportData) -> str:
        """Generate HTML report from structured data"""
        template = self._get_template()
        
        # Build HTML sections
        html = template
        
        # Replace placeholders
        html = html.replace("{{MATERIAL_NAME}}", data.material_formula_html or data.material_formula)
        html = html.replace("{{DATE}}", data.generation_date)
        html = html.replace("{{FORMULA_HTML}}", data.material_formula_html)
        
        # Build analysis section
        analysis_html = ""
        if data.analysis.get("crystal_system"):
            analysis_html += f'<div class="kv"><div class="k">Crystal System</div><div class="v">{data.analysis["crystal_system"]}</div></div>'
        if data.analysis.get("density"):
            analysis_html += f'<div class="kv"><div class="k">Density</div><div class="v">{self._format_units(data.analysis["density"])}</div></div>'
        if data.analysis.get("formation_energy"):
            analysis_html += f'<div class="kv"><div class="k">Formation Energy</div><div class="v">{self._format_units(data.analysis["formation_energy"])}</div></div>'
        if data.analysis.get("band_gap"):
            analysis_html += f'<div class="kv"><div class="k">Band Gap</div><div class="v">{data.analysis["band_gap"]}</div></div>'
        
        html = html.replace("{{ANALYSIS_PROPERTIES}}", analysis_html)
        
        # Build synthesis methods section
        methods_html = ""
        for i, method in enumerate(data.synthesis_methods, 1):
            methods_html += f'<div class="num"><span class="dot">{i}</span>{method["name"]}</div><ul class="list-tight">'
            for detail in method["details"]:
                methods_html += f'<li>{self._format_chemistry(detail)}</li>'
            methods_html += '</ul>'
        
        html = html.replace("{{SYNTHESIS_METHODS}}", methods_html or "<p>No direct synthesis methods found. Using analogous routes.</p>")
        
        # Build recommended procedure
        procedure_html = ""
        if data.recommended_procedure.get("steps"):
            for step in data.recommended_procedure["steps"]:
                procedure_html += f'''
                <div class="num">
                    <span class="dot">{step["number"]}</span>
                    {self._format_chemistry(step["description"])}
                </div>'''
        
        html = html.replace("{{PROCEDURE_STEPS}}", procedure_html or "<p>See synthesis methods above for recommended procedures.</p>")
        
        # Build critical parameters
        params_html = "<ul class='list-tight'>"
        for param in data.critical_parameters:
            params_html += f"<li>{self._format_chemistry(param)}</li>"
        params_html += "</ul>"
        
        html = html.replace("{{CRITICAL_PARAMS}}", params_html if data.critical_parameters else "<p>Standard solid-state synthesis parameters apply.</p>")
        
        # Build safety section
        safety_html = "<ul class='list-tight'>"
        for item in data.safety_considerations:
            safety_html += f"<li>{item}</li>"
        safety_html += "</ul>"
        
        html = html.replace("{{SAFETY_ITEMS}}", safety_html if data.safety_considerations else "<p>Standard laboratory safety procedures apply.</p>")
        
        # Build alternative routes
        alt_html = ""
        for i, route in enumerate(data.alternative_routes, 1):
            alt_html += f'''
            <div class="card">
                <h3>{i}. {route["name"]}</h3>
                <div class="kvs">
                    <div class="kv"><div class="k">Pros</div><div class="v">{route["pros"]}</div></div>
                    <div class="kv"><div class="k">Cons</div><div class="v">{route["cons"]}</div></div>
                </div>
            </div>'''
        
        html = html.replace("{{ALTERNATIVE_ROUTES}}", alt_html or "<p>See synthesis methods section for alternative approaches.</p>")
        
        # Build related materials chips
        chips_html = ""
        for material in data.related_materials[:8]:
            chips_html += f'<span class="chip">{self._formula_to_html(material)}</span>'
        
        html = html.replace("{{RELATED_MATERIALS}}", chips_html)
        
        # Add search metadata
        if data.confidence_score > 0:
            confidence_badge = "ok" if data.confidence_score > 0.8 else "warn" if data.confidence_score > 0.5 else "info"
            confidence_html = f'<span class="badge {confidence_badge}">Confidence: {data.confidence_score:.1%}</span>'
        else:
            confidence_html = ""
        
        html = html.replace("{{CONFIDENCE_BADGE}}", confidence_html)
        
        return html
    
    def _format_chemistry(self, text: str) -> str:
        """Format chemical text with proper subscripts/superscripts"""
        # Format temperatures
        text = re.sub(r'(\d+)\s*¬∞C', r'\1 ¬∞C', text)
        # Format chemical formulas
        text = re.sub(r'\b([A-Z][a-z]?)(\d+)', r'\1<sub>\2</sub>', text)
        # Format units
        text = self._format_units(text)
        return text
    
    def _format_units(self, text: str) -> str:
        """Format scientific units with proper HTML"""
        text = re.sub(r'cm-3', r'cm<sup>‚àí3</sup>', text)
        text = re.sub(r'g/cm3', r'g¬∑cm<sup>‚àí3</sup>', text)
        text = re.sub(r'atom-1', r'atom<sup>‚àí1</sup>', text)
        text = re.sub(r'eV/atom', r'eV¬∑atom<sup>‚àí1</sup>', text)
        text = re.sub(r'min-1', r'min<sup>‚àí1</sup>', text)
        text = re.sub(r'h-1', r'h<sup>‚àí1</sup>', text)
        text = re.sub(r'L/min', r'L¬∑min<sup>‚àí1</sup>', text)
        return text
    
    def _get_template(self) -> str:
        """Get HTML template"""
        if self.template_path.exists():
            return self.template_path.read_text()
        
        # Default template
        return '''<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>{{MATERIAL_NAME}} ‚Äî Synthesis Report</title>
  <style>
    :root{
      --bg:#0b1220;
      --ink:#0f172a;
      --ink-2:#1f2937;
      --muted:#6b7280;
      --fg:#0b1220;
      --card:#ffffff;
      --brand:#06b6d4;
      --brand-2:#22c55e;
      --accent:#6366f1;
      --warn:#f59e0b;
      --danger:#ef4444;
    }
    *{box-sizing:border-box}
    html,body{margin:0;padding:0;background:#f6f7fb;color:#0b1220;font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif;}
    .hero{background:linear-gradient(135deg,#0ea5e9, #22c55e 70%); color:#fff; padding:42px 24px; position:sticky; top:0; z-index:5; box-shadow:0 6px 20px rgba(0,0,0,.15)}
    .hero .title{display:flex;gap:12px;align-items:center;flex-wrap:wrap}
    .pill{display:inline-flex;align-items:center;gap:8px;padding:6px 10px;border-radius:999px;background:rgba(255,255,255,.18);backdrop-filter:saturate(150%) blur(2px);border:1px solid rgba(255,255,255,.28);font-weight:600}
    .container{max-width:1100px;margin:24px auto;padding:0 16px 64px}
    nav.toc{display:flex;flex-wrap:wrap;gap:8px;margin:16px 0 24px}
    nav.toc a{padding:8px 10px;border-radius:999px;background:#fff;border:1px solid #e5e7eb;text-decoration:none;color:#111827;font-size:14px}
    nav.toc a:hover{border-color:#cbd5e1}
    .grid{display:grid;gap:16px}
    @media(min-width:900px){.grid.cols-2{grid-template-columns:1fr 1fr}}
    .card{background:#fff;border:1px solid #e5e7eb;border-radius:16px; padding:18px 18px 16px; box-shadow:0 2px 8px rgba(2,6,23,.05)}
    h2{margin:6px 0 10px;font-size:22px}
    h3{margin:14px 0 8px;font-size:18px}
    p{line-height:1.55}
    .kvs{display:grid;grid-template-columns:180px 1fr;gap:8px; row-gap:10px}
    .kv{display:contents}
    .k{color:#374151}
    .v{font-weight:600}
    .chips{display:flex;flex-wrap:wrap;gap:6px;margin-top:8px}
    .chip{background:#f1f5f9;border:1px solid #e2e8f0;color:#0f172a;padding:4px 8px;border-radius:999px;font-size:13px}
    .badge{display:inline-flex;align-items:center;gap:6px;font-size:12px;font-weight:700;padding:4px 8px;border-radius:8px;border:1px solid #e5e7eb;background:#fff}
    .badge.ok{color:#16a34a;border-color:#bbf7d0;background:#f0fdf4}
    .badge.warn{color:#b45309;border-color:#fde68a;background:#fffbeb}
    .badge.info{color:#0369a1;border-color:#bae6fd;background:#f0f9ff}
    .list-tight li{margin:6px 0}
    .num{display:flex;align-items:center;gap:10px;margin:10px 0 6px;font-weight:800}
    .num .dot{display:inline-grid;place-items:center;width:26px;height:26px;border-radius:999px;background:#111827;color:#fff;font-size:13px}
    .callout{border-left:4px solid var(--accent); background:#eef2ff; padding:10px 12px;border-radius:10px}
    .muted{color:#6b7280}
    .toolbar{display:flex;gap:10px;margin-top:10px}
    .btn{border:1px solid #e5e7eb;background:#fff;border-radius:10px;padding:8px 10px;cursor:pointer}
    .btn:hover{background:#f8fafc}
    code,kbd{font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace}
    .two-col{columns:2; column-gap:20px}
    @media(max-width:800px){.two-col{columns:1}}
    .footer{margin-top:26px;color:#6b7280;font-size:13px;text-align:center}
    @media print { nav.toc, .toolbar { display:none } }
  </style>
</head>
<body>
  <header class="hero">
    <div class="title">
      <div style="font-size:28px;font-weight:900;letter-spacing:.2px">Synthesis Report: <span style="opacity:.95">{{MATERIAL_NAME}}</span></div>
      <span class="pill">üìÖ {{DATE}}</span>
      <span class="pill">üß™ SKY Agent Analysis</span>
      {{CONFIDENCE_BADGE}}
    </div>
    <div class="toolbar">
      <button class="btn" onclick="window.print()">üñ®Ô∏è Print / Save as PDF</button>
      <button class="btn" onclick="window.scrollTo({top:0,behavior:'smooth'})">‚¨ÜÔ∏è Back to Top</button>
    </div>
  </header>

  <div class="container">
    <nav class="toc">
      <a href="#overview">Overview</a>
      <a href="#methods">Synthesis Methods</a>
      <a href="#procedure">Recommended Procedure</a>
      <a href="#critical">Critical Parameters</a>
      <a href="#safety">Safety</a>
      <a href="#alternatives">Alternative Routes</a>
    </nav>

    <section id="overview" class="card">
      <h2>üìä Target Material Analysis</h2>
      <div class="kvs">
        <div class="kv"><div class="k">Formula</div><div class="v">{{FORMULA_HTML}}</div></div>
        {{ANALYSIS_PROPERTIES}}
      </div>
      <div class="chips">{{RELATED_MATERIALS}}</div>
    </section>

    <section id="methods" class="card">
      <h2>üî¨ Synthesis Methods</h2>
      {{SYNTHESIS_METHODS}}
    </section>

    <section id="procedure" class="card">
      <h2>üß™ Recommended Procedure</h2>
      {{PROCEDURE_STEPS}}
    </section>

    <section id="critical" class="card">
      <h2>‚öôÔ∏è Critical Parameters</h2>
      {{CRITICAL_PARAMS}}
    </section>

    <section id="safety" class="card">
      <h2>‚ö†Ô∏è Safety Considerations</h2>
      {{SAFETY_ITEMS}}
    </section>

    <section id="alternatives" class="grid cols-2">
      <h2 style="grid-column:1/-1">üìù Alternative Routes</h2>
      {{ALTERNATIVE_ROUTES}}
    </section>

    <div class="footer">
      Generated by SKY (Synthesis Knowledge Yield) Agent ‚Ä¢ Powered by Materials Project
    </div>
  </div>
</body>
</html>'''
    
    def save_report(self, data: SynthesisReportData, output_path: Path) -> Path:
        """Generate and save HTML report to file"""
        html = self.generate_html(data)
        output_path = Path(output_path)
        output_path.write_text(html, encoding='utf-8')
        return output_path
    
    def from_agent_output(self, raw_output: str, output_path: Optional[Path] = None) -> Path:
        """Convenience method to generate report directly from agent output"""
        data = self.parse_agent_output(raw_output)
        
        if output_path is None:
            # Default filename based on material formula
            safe_name = re.sub(r'[^\w\s-]', '', data.material_formula)
            output_path = Path(f"{safe_name}_synthesis_report.html")
        
        return self.save_report(data, output_path)
```


================================================================================
=== FILE: sky\report\__init__.py ===
================================================================================

```python

```


================================================================================
=== FILE: sky_mcp\paths.py ===
================================================================================

```python
from __future__ import annotations

import os
from pathlib import Path
from typing import Iterable, List, Optional

from src import ASSETS_DIR

DEFAULT_MAX_FILE_BYTES = 2_000_000


class PathResolutionError(RuntimeError):
    def __init__(self, error_type: str, message: str, details: Optional[dict] = None):
        super().__init__(message)
        self.error_type = error_type
        self.message = message
        self.details = details or {}


def _parse_max_bytes() -> int:
    value = os.getenv("SKY_MCP_MAX_FILE_BYTES")
    if not value:
        return DEFAULT_MAX_FILE_BYTES
    try:
        parsed = int(value)
        return parsed if parsed > 0 else DEFAULT_MAX_FILE_BYTES
    except ValueError:
        return DEFAULT_MAX_FILE_BYTES


def _default_allowed_roots() -> List[Path]:
    repo_root = Path(__file__).resolve().parents[1]
    roots = [repo_root, ASSETS_DIR, Path.cwd()]
    extra = os.getenv("SKY_MCP_ALLOWED_ROOTS")
    if extra:
        for raw in extra.split(os.pathsep):
            raw = raw.strip()
            if raw:
                roots.append(Path(raw))
    return roots


def resolve_local_path(
    path_str: str,
    allowed_roots: Optional[Iterable[Path]] = None,
    max_bytes: Optional[int] = None,
) -> Path:
    if not path_str or not str(path_str).strip():
        raise PathResolutionError("invalid_input", "Path is required.")

    try:
        candidate = Path(path_str).expanduser()
    except Exception as exc:
        raise PathResolutionError(
            "invalid_input", "Invalid path string.", details={"error": str(exc)}
        ) from exc

    resolved = candidate.resolve(strict=False)
    roots = list(allowed_roots) if allowed_roots is not None else _default_allowed_roots()
    resolved_roots = [Path(root).expanduser().resolve(strict=False) for root in roots]

    if not any(resolved.is_relative_to(root) for root in resolved_roots):
        raise PathResolutionError(
            "permission_denied",
            "Path is outside allowed roots.",
            details={
                "path": str(resolved),
                "allowed_roots": [str(r) for r in resolved_roots],
            },
        )

    if not resolved.exists():
        raise PathResolutionError(
            "file_not_found",
            "File not found.",
            details={"path": str(resolved)},
        )

    if not resolved.is_file():
        raise PathResolutionError(
            "invalid_input",
            "Path is not a file.",
            details={"path": str(resolved)},
        )

    limit = max_bytes if max_bytes is not None else _parse_max_bytes()
    try:
        size = resolved.stat().st_size
    except OSError as exc:
        raise PathResolutionError(
            "runtime_error",
            "Unable to stat file.",
            details={"path": str(resolved), "error": str(exc)},
        ) from exc

    if size > limit:
        raise PathResolutionError(
            "file_too_large",
            "File exceeds size limit.",
            details={"path": str(resolved), "size": size, "max_bytes": limit},
        )

    return resolved

```


================================================================================
=== FILE: sky_mcp\report_io.py ===
================================================================================

```python
from __future__ import annotations

import os
import re
import tempfile
from pathlib import Path
from typing import Callable
from uuid import uuid4


def _slugify(text: str, max_len: int = 50) -> str:
    slug = re.sub(r"[^A-Za-z0-9_-]+", "_", text or "").strip("_")
    if not slug:
        slug = "report"
    return slug[:max_len]


def build_report_path(
    query: str,
    reports_dir: Path,
    uuid_func: Callable[[], object] = uuid4,
) -> Path:
    slug = _slugify(query)
    uid = str(uuid_func())
    filename = f"{slug}_{uid}.html"
    return reports_dir / filename


def atomic_write_text(target_path: Path, content: str) -> None:
    target_path.parent.mkdir(parents=True, exist_ok=True)
    with tempfile.NamedTemporaryFile(
        mode="w",
        encoding="utf-8",
        delete=False,
        dir=str(target_path.parent),
        prefix=target_path.stem + "_",
        suffix=".tmp",
    ) as tmp:
        tmp.write(content)
        temp_name = tmp.name
    os.replace(temp_name, target_path)

```


================================================================================
=== FILE: sky_mcp\response.py ===
================================================================================

```python
from __future__ import annotations

from typing import Any, Dict, Optional

ALLOWED_ERROR_TYPES = {
    "missing_env",
    "file_not_found",
    "invalid_input",
    "permission_denied",
    "file_too_large",
    "mp_api_error",
    "upstream_timeout",
    "upstream_rate_limited",
    "runtime_error",
}


def _envelope(
    ok: bool,
    data: Any,
    error: Optional[Dict[str, Any]],
    meta: Optional[Dict[str, Any]],
    provenance: Optional[Dict[str, Any]],
) -> Dict[str, Any]:
    return {
        "ok": ok,
        "data": data,
        "error": error,
        "meta": meta or {},
        "provenance": provenance or {},
    }


def validate_envelope(resp: Dict[str, Any], strict: bool = False) -> Dict[str, Any]:
    try:
        assert isinstance(resp, dict), "Envelope must be a dict."
        assert "ok" in resp, "Envelope missing ok."
        assert "data" in resp, "Envelope missing data."
        assert "error" in resp, "Envelope missing error."
        assert "meta" in resp, "Envelope missing meta."
        assert "provenance" in resp, "Envelope missing provenance."
        assert isinstance(resp["meta"], dict), "meta must be dict."
        assert isinstance(resp["provenance"], dict), "provenance must be dict."
        if resp["ok"] is True:
            assert resp["error"] is None, "ok True requires error=None."
        else:
            assert resp["data"] is None, "ok False requires data=None."
            assert isinstance(resp["error"], dict), "error must be dict."
            for key in ("type", "message", "details"):
                assert key in resp["error"], f"error missing {key}."
            err_type = resp["error"]["type"]
            assert err_type in ALLOWED_ERROR_TYPES, f"Invalid error.type: {err_type}"
        return resp
    except AssertionError as exc:
        if strict:
            raise
        return _envelope(
            False,
            None,
            {
                "type": "runtime_error",
                "message": "Envelope validation failed.",
                "details": str(exc),
            },
            meta={},
            provenance={},
        )


def make_ok(
    data: Any,
    meta: Optional[Dict[str, Any]] = None,
    provenance: Optional[Dict[str, Any]] = None,
) -> Dict[str, Any]:
    resp = _envelope(True, data, None, meta, provenance)
    return validate_envelope(resp, strict=False)


def make_err(
    error_type: str,
    message: str,
    details: Any = None,
    meta: Optional[Dict[str, Any]] = None,
    provenance: Optional[Dict[str, Any]] = None,
) -> Dict[str, Any]:
    resp = _envelope(
        False,
        None,
        {"type": error_type, "message": message, "details": details},
        meta,
        provenance,
    )
    return validate_envelope(resp, strict=False)

```


================================================================================
=== FILE: sky_mcp\server.py ===
================================================================================

```python
from __future__ import annotations

import inspect
from typing import Callable, List, Tuple

from sky_mcp import tools


ToolDef = Tuple[str, Callable[..., dict], str]


TOOL_DEFS: List[ToolDef] = [
    ("capabilities", tools.capabilities, "Report available assets, env vars, and versions."),
    ("search_similar_by_composition", tools.search_similar_by_composition, "Find similar materials by composition."),
    (
        "search_similar_by_structure_cif",
        tools.search_similar_by_structure_cif,
        "Find similar materials by CIF text (canonical).",
    ),
    (
        "search_similar_by_structure_path",
        tools.search_similar_by_structure_path,
        "Find similar materials by CIF file path (local-only).",
    ),
    ("read_cif", tools.read_cif, "Read CIF text and return structure metadata."),
    ("read_cif_path", tools.read_cif_path, "Read CIF file path and return structure metadata (local-only)."),
    ("get_material_properties", tools.get_material_properties, "Fetch Materials Project properties."),
    ("get_synthesis_recipes", tools.get_synthesis_recipes, "Retrieve synthesis recipes for a formula."),
    (
        "analyze_synthesis_parameters",
        tools.analyze_synthesis_parameters,
        "Extract synthesis parameters from text.",
    ),
    (
        "recursive_synthesis_search",
        tools.recursive_synthesis_search,
        "Recursive synthesis search using similarity neighbors.",
    ),
    (
        "discover_synthesis_report",
        tools.discover_synthesis_report,
        "Expensive, networked, nondeterministic synthesis report.",
    ),
    ("self_check", tools.self_check, "Run deterministic checks for MCP readiness."),
]


def _supports_named(tool_func: Callable[..., object]) -> bool:
    try:
        sig = inspect.signature(tool_func)
    except (TypeError, ValueError):
        return False
    return "name" in sig.parameters


def _register_tools(tool_decorator_factory: Callable[..., Callable[[Callable[..., dict]], Callable[..., dict]]]):
    supports_named = _supports_named(tool_decorator_factory)
    for name, func, description in TOOL_DEFS:
        if supports_named:
            decorator = tool_decorator_factory(name=name, description=description)
        else:
            decorator = tool_decorator_factory()
        decorator(func)


def _try_fastmcp():
    try:
        from mcp.server.fastmcp import FastMCP

        mcp = FastMCP("sky")
        _register_tools(mcp.tool)

        def _run():
            mcp.run()

        return _run
    except Exception:
        return None


async def _run_stdio():
    from mcp.server import Server
    from mcp.server.stdio import stdio_server

    server = Server("sky")
    _register_tools(server.tool)

    async with stdio_server() as (read, write):
        await server.run(read, write)


def main() -> None:
    fastmcp_runner = _try_fastmcp()
    if fastmcp_runner is not None:
        fastmcp_runner()
        return

    import anyio

    anyio.run(_run_stdio)


if __name__ == "__main__":
    main()

```


================================================================================
=== FILE: sky_mcp\tools.py ===
================================================================================

```python
from __future__ import annotations

import os
import re
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional

from monty.serialization import loadfn
from pymatgen.core import Composition, Structure

from src import ASSETS_DIR
from src.utils.assets import find_asset
from sky_mcp.paths import PathResolutionError, resolve_local_path
from sky_mcp.report_io import atomic_write_text, build_report_path
from sky_mcp.response import make_err, make_ok


def _get_sky_version() -> str:
    try:
        import sky

        return getattr(sky, "__version__", "unknown") or "unknown"
    except Exception:
        pass
    try:
        import tomllib

        pyproject = Path(__file__).resolve().parents[1] / "pyproject.toml"
        data = tomllib.loads(pyproject.read_text(encoding="utf-8"))
        return str(data.get("project", {}).get("version", "unknown"))
    except Exception:
        return "unknown"


def _meta(tool_name: str, warnings: Optional[List[str]] = None) -> Dict[str, Any]:
    return {
        "tool": tool_name,
        "version": _get_sky_version(),
        "warnings": warnings or [],
    }


def _missing_asset_error(
    tool_name: str, base: Path, preferred: Iterable[str], globs: Iterable[str]
) -> Dict[str, Any]:
    return make_err(
        "file_not_found",
        "Required asset not found.",
        details={
            "base_dir": str(base),
            "preferred_names": list(preferred),
            "globs": list(globs),
        },
        meta=_meta(tool_name),
    )


def _composition_embedding_path() -> Optional[Path]:
    return find_asset(
        preferred_names=["mp_dataset_composition_magpie.h5"],
        globs=["*composition*.h5"],
        base=ASSETS_DIR / "embedding",
    )


def _structure_embedding_path() -> Optional[Path]:
    return find_asset(
        preferred_names=["mp_dataset_structure_mace.h5"],
        globs=["*structure*.h5"],
        base=ASSETS_DIR / "embedding",
    )


def _recipes_dataset_path() -> Optional[Path]:
    return find_asset(
        preferred_names=["mp_synthesis_recipes.json.gz"],
        globs=["*synthesis*recipes*.json*"],
        base=ASSETS_DIR,
    )


def _derived_similarity(distance: float) -> float:
    return 1.0 / (1.0 + float(distance))


def _parse_cif_text(cif: str) -> Structure:
    if not cif or not cif.strip():
        raise ValueError("CIF text is empty.")
    return Structure.from_str(cif, fmt="cif")


def _structure_summary(structure: Structure) -> Dict[str, Any]:
    sites = [
        {
            "element": site.species_string,
            "frac_coords": [float(x) for x in site.frac_coords],
        }
        for site in structure.sites
    ]
    sites.sort(key=lambda s: (s["element"], tuple(s["frac_coords"])))
    return {
        "formula": structure.composition.formula,
        "reduced_formula": structure.composition.reduced_formula,
        "density": structure.density,
        "num_sites": structure.num_sites,
        "lattice": {
            "a": structure.lattice.a,
            "b": structure.lattice.b,
            "c": structure.lattice.c,
            "alpha": structure.lattice.alpha,
            "beta": structure.lattice.beta,
            "gamma": structure.lattice.gamma,
            "volume": structure.lattice.volume,
        },
        "elements": sorted(str(el) for el in structure.composition.elements),
        "sites": sites,
    }

def _list_asset_files(base: Path, globs: Iterable[str]) -> List[str]:
    files: List[str] = []
    if base.exists():
        for pattern in globs:
            for match in base.glob(pattern):
                if match.is_file():
                    files.append(match.name)
    return sorted(set(files))


def capabilities() -> Dict[str, Any]:
    tool_name = "capabilities"
    comp_embedding = _composition_embedding_path()
    struct_embedding = _structure_embedding_path()
    recipes_dataset = _recipes_dataset_path()
    openai_key = os.getenv("OPENAI_MDG_API_KEY") or os.getenv("OPENAI_API_KEY")
    mp_key = os.getenv("MP_API_KEY")

    try:
        import pymatgen

        pymatgen_version = getattr(pymatgen, "__version__", "unknown")
    except Exception:
        pymatgen_version = "unknown"
    try:
        import mcp

        mcp_version = getattr(mcp, "__version__", "unknown")
    except Exception:
        mcp_version = "unknown"

    return make_ok(
        {
            "assets": {
                "composition_embedding": bool(comp_embedding and comp_embedding.exists()),
                "structure_embedding": bool(struct_embedding and struct_embedding.exists()),
                "recipes_dataset": bool(recipes_dataset and recipes_dataset.exists()),
                "files": {
                    "composition_embeddings": _list_asset_files(
                        ASSETS_DIR / "embedding", ["*composition*.h5"]
                    ),
                    "structure_embeddings": _list_asset_files(
                        ASSETS_DIR / "embedding", ["*structure*.h5"]
                    ),
                    "recipes_datasets": _list_asset_files(
                        ASSETS_DIR, ["*synthesis*recipes*.json*"]
                    ),
                },
            },
            "env": {
                "mp_api_key": bool(mp_key),
                "openai_api_key": bool(openai_key),
            },
            "versions": {
                "sky_version": _get_sky_version(),
                "pymatgen_version": pymatgen_version,
                "mcp_version": mcp_version,
            },
        },
        meta=_meta(tool_name),
        provenance={"source": "local", "ids": []},
    )


def read_cif(cif: str) -> Dict[str, Any]:
    tool_name = "read_cif"
    try:
        structure = _parse_cif_text(cif)
        data = _structure_summary(structure)
        return make_ok(
            data,
            meta=_meta(tool_name),
            provenance={"source": "local", "ids": []},
        )
    except Exception as exc:
        return make_err(
            "invalid_input",
            "Failed to parse CIF text.",
            details=str(exc),
            meta=_meta(tool_name),
        )


def read_cif_path(cif_path: str) -> Dict[str, Any]:
    tool_name = "read_cif_path"
    try:
        path = resolve_local_path(cif_path)
    except PathResolutionError as exc:
        return make_err(
            exc.error_type,
            exc.message,
            details=exc.details,
            meta=_meta(tool_name),
        )
    try:
        structure = Structure.from_file(path)
        data = _structure_summary(structure)
        return make_ok(
            data,
            meta=_meta(tool_name),
            provenance={"source": "local", "ids": []},
        )
    except Exception as exc:
        return make_err(
            "runtime_error",
            "Failed to read CIF file.",
            details=str(exc),
            meta=_meta(tool_name),
        )


def search_similar_by_composition(formula: str, top_n: int = 10) -> Dict[str, Any]:
    tool_name = "search_similar_by_composition"
    if not formula or not formula.strip():
        return make_err(
            "invalid_input",
            "Formula is required.",
            meta=_meta(tool_name),
        )
    try:
        composition = Composition(formula)
    except Exception as exc:
        return make_err(
            "invalid_input",
            "Invalid formula.",
            details=str(exc),
            meta=_meta(tool_name),
        )

    embedding_path = _composition_embedding_path()
    if not embedding_path:
        return _missing_asset_error(
            tool_name,
            base=ASSETS_DIR / "embedding",
            preferred=["mp_dataset_composition_magpie.h5"],
            globs=["*composition*.h5"],
        )

    try:
        from src.embedding import InputType
        from src.search_api import SearchAPI

        search_api = SearchAPI(input_type=InputType.COMPOSITION, max_neighbors=max(100, top_n))
        neighbors = search_api.query(composition, n_neighbors=top_n)
        neighbors = sorted(neighbors, key=lambda n: (n.distance, n.material_id, n.formula))
        results = []
        for idx, neighbor in enumerate(neighbors, start=1):
            results.append(
                {
                    "rank": idx,
                    "material_id": neighbor.material_id,
                    "formula": neighbor.formula,
                    "distance": neighbor.distance,
                    "similarity": _derived_similarity(neighbor.distance),
                }
            )
        return make_ok(
            {
                "query": formula,
                "num_results": len(results),
                "neighbors": results,
            },
            meta=_meta(tool_name),
            provenance={
                "source": "computed",
                "ids": [n["material_id"] for n in results],
            },
        )
    except FileNotFoundError as exc:
        return make_err(
            "file_not_found",
            "Embedding dataset not found.",
            details=str(exc),
            meta=_meta(tool_name),
        )
    except Exception as exc:
        return make_err(
            "runtime_error",
            "Similarity search failed.",
            details=str(exc),
            meta=_meta(tool_name),
        )


def search_similar_by_structure_cif(cif: str, top_n: int = 10) -> Dict[str, Any]:
    tool_name = "search_similar_by_structure_cif"
    try:
        structure = _parse_cif_text(cif)
    except Exception as exc:
        return make_err(
            "invalid_input",
            "Failed to parse CIF text.",
            details=str(exc),
            meta=_meta(tool_name),
        )

    embedding_path = _structure_embedding_path()
    if not embedding_path:
        return _missing_asset_error(
            tool_name,
            base=ASSETS_DIR / "embedding",
            preferred=["mp_dataset_structure_mace.h5"],
            globs=["*structure*.h5"],
        )

    try:
        from src.embedding import InputType
        from src.search_api import SearchAPI

        search_api = SearchAPI(input_type=InputType.STRUCTURE, max_neighbors=max(100, top_n))
        neighbors = search_api.query(structure, n_neighbors=top_n)
        neighbors = sorted(neighbors, key=lambda n: (n.distance, n.material_id, n.formula))
        results = []
        for idx, neighbor in enumerate(neighbors, start=1):
            results.append(
                {
                    "rank": idx,
                    "material_id": neighbor.material_id,
                    "formula": neighbor.formula,
                    "distance": neighbor.distance,
                    "similarity": _derived_similarity(neighbor.distance),
                }
            )
        return make_ok(
            {
                "num_results": len(results),
                "neighbors": results,
            },
            meta=_meta(tool_name),
            provenance={
                "source": "computed",
                "ids": [n["material_id"] for n in results],
            },
        )
    except FileNotFoundError as exc:
        return make_err(
            "file_not_found",
            "Embedding dataset not found.",
            details=str(exc),
            meta=_meta(tool_name),
        )
    except Exception as exc:
        return make_err(
            "runtime_error",
            "Similarity search failed.",
            details=str(exc),
            meta=_meta(tool_name),
        )


def search_similar_by_structure_path(cif_path: str, top_n: int = 10) -> Dict[str, Any]:
    tool_name = "search_similar_by_structure_path"
    try:
        path = resolve_local_path(cif_path)
    except PathResolutionError as exc:
        return make_err(
            exc.error_type,
            exc.message,
            details=exc.details,
            meta=_meta(tool_name),
        )
    try:
        structure = Structure.from_file(path)
    except Exception as exc:
        return make_err(
            "runtime_error",
            "Failed to read CIF file.",
            details=str(exc),
            meta=_meta(tool_name),
        )

    embedding_path = _structure_embedding_path()
    if not embedding_path:
        return _missing_asset_error(
            tool_name,
            base=ASSETS_DIR / "embedding",
            preferred=["mp_dataset_structure_mace.h5"],
            globs=["*structure*.h5"],
        )

    try:
        from src.embedding import InputType
        from src.search_api import SearchAPI

        search_api = SearchAPI(input_type=InputType.STRUCTURE, max_neighbors=max(100, top_n))
        neighbors = search_api.query(structure, n_neighbors=top_n)
        neighbors = sorted(neighbors, key=lambda n: (n.distance, n.material_id, n.formula))
        results = []
        for idx, neighbor in enumerate(neighbors, start=1):
            results.append(
                {
                    "rank": idx,
                    "material_id": neighbor.material_id,
                    "formula": neighbor.formula,
                    "distance": neighbor.distance,
                    "similarity": _derived_similarity(neighbor.distance),
                }
            )
        return make_ok(
            {
                "num_results": len(results),
                "neighbors": results,
            },
            meta=_meta(tool_name),
            provenance={
                "source": "computed",
                "ids": [n["material_id"] for n in results],
            },
        )
    except FileNotFoundError as exc:
        return make_err(
            "file_not_found",
            "Embedding dataset not found.",
            details=str(exc),
            meta=_meta(tool_name),
        )
    except Exception as exc:
        return make_err(
            "runtime_error",
            "Similarity search failed.",
            details=str(exc),
            meta=_meta(tool_name),
        )


def get_material_properties(material_ids: List[str]) -> Dict[str, Any]:
    tool_name = "get_material_properties"
    if not material_ids:
        return make_err(
            "invalid_input",
            "material_ids must be a non-empty list.",
            meta=_meta(tool_name),
        )
    mp_key = os.getenv("MP_API_KEY")
    if not mp_key:
        return make_err(
            "missing_env",
            "MP_API_KEY not found in environment.",
            meta=_meta(tool_name),
        )
    try:
        from mp_api.client import MPRester

        results = []
        with MPRester(mp_key) as mpr:
            docs = mpr.materials.summary.search(material_ids=material_ids)
            for doc in docs:
                results.append(
                    {
                        "material_id": doc.material_id,
                        "formula_pretty": doc.formula_pretty,
                        "band_gap": doc.band_gap,
                        "density": doc.density,
                        "formation_energy_per_atom": doc.formation_energy_per_atom,
                        "energy_above_hull": doc.energy_above_hull,
                        "volume": doc.volume if hasattr(doc, "volume") else None,
                        "mp_url": f"https://materialsproject.org/materials/{doc.material_id}",
                    }
                )
        results = sorted(results, key=lambda r: r["material_id"])
        return make_ok(
            results,
            meta=_meta(tool_name),
            provenance={"source": "mp", "ids": [r["material_id"] for r in results]},
        )
    except Exception as exc:
        return make_err(
            "mp_api_error",
            "Failed to fetch material properties from Materials Project.",
            details=str(exc),
            meta=_meta(tool_name),
        )


def get_synthesis_recipes(formula: str, max_recipes: int = 5) -> Dict[str, Any]:
    tool_name = "get_synthesis_recipes"
    if not formula or not formula.strip():
        return make_err(
            "invalid_input",
            "Formula is required.",
            meta=_meta(tool_name),
        )
    try:
        target_comp = Composition(formula)
    except Exception as exc:
        return make_err(
            "invalid_input",
            "Invalid formula.",
            details=str(exc),
            meta=_meta(tool_name),
        )

    recipes_path = _recipes_dataset_path()
    if recipes_path and recipes_path.exists():
        try:
            all_recipes = loadfn(recipes_path)
            matched = []
            for recipe in all_recipes:
                target_formula = recipe.get("target_formula")
                if not target_formula:
                    continue
                try:
                    recipe_comp = Composition(target_formula)
                except Exception:
                    continue
                if recipe_comp.reduced_formula == target_comp.reduced_formula:
                    matched.append(recipe)
            matched.sort(
                key=lambda r: (
                    r.get("target_formula", ""),
                    r.get("doi", ""),
                    r.get("paragraph_string", ""),
                    r.get("reaction_string", ""),
                )
            )
            data = {
                "target_formula": formula,
                "recipes_found": len(matched),
                "recipes": matched[:max_recipes],
            }
            return make_ok(
                data,
                meta=_meta(tool_name),
                provenance={"source": "local", "ids": []},
            )
        except Exception as exc:
            return make_err(
                "runtime_error",
                "Failed to load local synthesis dataset.",
                details=str(exc),
                meta=_meta(tool_name),
            )

    MissingEnv = None
    try:
        from src.agent import MissingEnvError as _MissingEnvError, SynthesisAgent

        MissingEnv = _MissingEnvError
        agent = SynthesisAgent()
        recipes = agent.get_synthesis_recipes_by_formula(formula)
        results = []
        for recipe in recipes[:max_recipes]:
            if hasattr(recipe, "model_dump"):
                results.append(recipe.model_dump())
            elif hasattr(recipe, "dict"):
                results.append(recipe.dict())
            else:
                results.append(recipe)
        results = sorted(
            results,
            key=lambda r: (
                r.get("target_formula", ""),
                r.get("doi", ""),
                r.get("paragraph_string", ""),
            )
            if isinstance(r, dict)
            else str(r),
        )
        return make_ok(
            {
                "target_formula": formula,
                "recipes_found": len(results),
                "recipes": results,
            },
            meta=_meta(tool_name),
            provenance={"source": "mp", "ids": []},
        )
    except Exception as exc:
        if MissingEnv and isinstance(exc, MissingEnv):
            return make_err(
                "missing_env",
                str(exc),
                meta=_meta(tool_name),
            )
        return make_err(
            "runtime_error",
            "Recipe retrieval failed. The Materials Project recipe route may be unavailable.",
            details=str(exc),
            meta=_meta(tool_name),
        )


def analyze_synthesis_parameters(text: str) -> Dict[str, Any]:
    tool_name = "analyze_synthesis_parameters"
    if not text or not text.strip():
        return make_err(
            "invalid_input",
            "text is required.",
            meta=_meta(tool_name),
        )

    temperature_patterns = [
        r"(\d+)\s*¬∞C",
        r"(\d+)\s*K",
        r"(\d+)\s*degrees?\s*C",
        r"(\d+)\s*celsius",
    ]
    temperatures = []
    for pattern in temperature_patterns:
        temperatures.extend(re.findall(pattern, text, flags=re.IGNORECASE))

    time_patterns = [
        r"(\d+)\s*hours?",
        r"(\d+)\s*h\b",
        r"(\d+)\s*minutes?",
        r"(\d+)\s*min\b",
        r"(\d+)\s*days?",
    ]
    times = []
    for pattern in time_patterns:
        times.extend(re.findall(pattern, text, flags=re.IGNORECASE))

    methods = {
        "solid_state": ["solid state", "ceramic", "calcination", "sintering"],
        "sol_gel": ["sol-gel", "sol gel", "gelation", "xerogel"],
        "hydrothermal": ["hydrothermal", "solvothermal", "autoclave"],
        "precipitation": ["precipitation", "coprecipitation", "co-precipitation"],
        "cvd": ["cvd", "chemical vapor", "vapor deposition"],
        "combustion": ["combustion", "self-propagating", "shs"],
        "flux": ["flux", "molten salt", "flux growth"],
    }
    detected_methods = []
    lower = text.lower()
    for method, keywords in methods.items():
        if any(keyword in lower for keyword in keywords):
            detected_methods.append(method)

    atmospheres = []
    for keyword in ["air", "argon", "nitrogen", "n2", "ar", "oxygen", "o2", "vacuum", "inert"]:
        if keyword in lower:
            atmospheres.append(keyword)

    data = {
        "temperatures_C": sorted(set(temperatures)),
        "time_durations": sorted(set(times)),
        "synthesis_methods": sorted(set(detected_methods)),
        "atmosphere": sorted(set(atmospheres)),
        "has_heating": bool(temperatures),
        "text_length": len(text),
    }
    return make_ok(
        data,
        meta=_meta(tool_name),
        provenance={"source": "computed", "ids": []},
    )


def recursive_synthesis_search(
    formula: str,
    max_depth: int = 3,
    min_confidence: float = 0.7,
    n_initial_neighbors: int = 30,
) -> Dict[str, Any]:
    tool_name = "recursive_synthesis_search"
    if not formula or not formula.strip():
        return make_err(
            "invalid_input",
            "Formula is required.",
            meta=_meta(tool_name),
        )
    try:
        Composition(formula)
    except Exception as exc:
        return make_err(
            "invalid_input",
            "Invalid formula.",
            details=str(exc),
            meta=_meta(tool_name),
        )

    embedding_path = _composition_embedding_path()
    if not embedding_path:
        return _missing_asset_error(
            tool_name,
            base=ASSETS_DIR / "embedding",
            preferred=["mp_dataset_composition_magpie.h5"],
            globs=["*composition*.h5"],
        )

    if not os.getenv("MP_API_KEY"):
        return make_err(
            "missing_env",
            "MP_API_KEY not found in environment.",
            meta=_meta(tool_name),
        )

    MissingEnv = None
    try:
        from src.agent import MissingEnvError as _MissingEnvError, SynthesisAgent
        from src.recursive_synthesis import RecursiveSynthesisSearch

        MissingEnv = _MissingEnvError
        recursive_search = RecursiveSynthesisSearch(
            synthesis_agent=SynthesisAgent(),
            max_depth=max_depth,
            min_confidence=min_confidence,
            verbose=False,
        )
        results = recursive_search.search(
            target_formula=formula,
            n_initial_neighbors=n_initial_neighbors,
        )
        return make_ok(
            results,
            meta=_meta(tool_name),
            provenance={"source": "computed", "ids": []},
        )
    except Exception as exc:
        if MissingEnv and isinstance(exc, MissingEnv):
            return make_err(
                "missing_env",
                str(exc),
                meta=_meta(tool_name),
            )
        return make_err(
            "runtime_error",
            "Recursive synthesis search failed.",
            details=str(exc),
            meta=_meta(tool_name),
        )


def discover_synthesis_report(query: str, html: bool = False) -> Dict[str, Any]:
    tool_name = "discover_synthesis_report"
    openai_key = os.getenv("OPENAI_MDG_API_KEY") or os.getenv("OPENAI_API_KEY")
    if not openai_key:
        return make_err(
            "missing_env",
            "OPENAI_API_KEY or OPENAI_MDG_API_KEY not found in environment.",
            meta=_meta(tool_name),
        )

    warnings = ["networked", "nondeterministic", "may incur cost"]
    try:
        from sky.core.synthesis_agent import SKYSynthesisAgent
        from sky.report.html_generator import HTMLReportGenerator

        agent = SKYSynthesisAgent()
        analysis_text = agent.discover_synthesis_sync(query)

        data: Dict[str, Any] = {"analysis_text": analysis_text}
        if html:
            generator = HTMLReportGenerator()
            report_data = generator.parse_agent_output(analysis_text)
            if not report_data.material_formula:
                report_data.material_formula = query
                report_data.material_formula_html = generator._formula_to_html(query)
            html_content = generator.generate_html(report_data)
            reports_dir = Path.cwd() / "sky_reports"
            output_path = build_report_path(query, reports_dir)
            atomic_write_text(output_path, html_content)
            data["report_path"] = str(output_path.relative_to(Path.cwd()))

        provenance: Dict[str, Any] = {"source": "openai", "outputs": []}
        if "report_path" in data:
            provenance["outputs"] = [data["report_path"]]

        return make_ok(
            data,
            meta=_meta(tool_name, warnings=warnings),
            provenance=provenance,
        )
    except Exception as exc:
        return make_err(
            "runtime_error",
            "Synthesis report generation failed.",
            details=str(exc),
            meta=_meta(tool_name, warnings=warnings),
        )


def self_check() -> Dict[str, Any]:
    tool_name = "self_check"
    comp_embedding = _composition_embedding_path()
    struct_embedding = _structure_embedding_path()
    recipes_dataset = _recipes_dataset_path()
    openai_key = os.getenv("OPENAI_MDG_API_KEY") or os.getenv("OPENAI_API_KEY")
    mp_key = os.getenv("MP_API_KEY")
    reports_dir = Path.cwd() / "sky_reports"
    reports_dir_writable = reports_dir.exists() and os.access(reports_dir, os.W_OK)
    if not reports_dir.exists():
        reports_dir_writable = os.access(reports_dir.parent, os.W_OK)

    tools = sorted(
        [
            "capabilities",
            "search_similar_by_composition",
            "search_similar_by_structure_cif",
            "search_similar_by_structure_path",
            "read_cif",
            "read_cif_path",
            "get_material_properties",
            "get_synthesis_recipes",
            "analyze_synthesis_parameters",
            "recursive_synthesis_search",
            "discover_synthesis_report",
            "self_check",
        ]
    )

    return make_ok(
        {
            "tools": tools,
            "assets": {
                "composition_embedding": bool(comp_embedding and comp_embedding.exists()),
                "structure_embedding": bool(struct_embedding and struct_embedding.exists()),
                "recipes_dataset": bool(recipes_dataset and recipes_dataset.exists()),
            },
            "report_dir_writable": bool(reports_dir_writable),
            "env": {
                "mp_api_key": bool(mp_key),
                "openai_api_key": bool(openai_key),
            },
        },
        meta=_meta(tool_name),
        provenance={"source": "local", "ids": []},
    )

```


================================================================================
=== FILE: sky_mcp\__init__.py ===
================================================================================

```python
"""MCP server package for SKY."""


```


================================================================================
=== FILE: src\agent.py ===
================================================================================

```python
import os

from pymatgen.core import Composition, Structure
from src.embedding import InputType
from src.search_api import SearchAPI
from src.schema import Neighbor, SynthesisRecipe, SummaryDoc


class MissingEnvError(RuntimeError):
    pass


class SynthesisAgent:
    def __init__(self):
        self._search_api_composition = None
        self._search_api_structure = None
        self._mpr = None

    def _get_search_api_composition(self) -> SearchAPI:
        if self._search_api_composition is None:
            self._search_api_composition = SearchAPI(
                input_type=InputType.COMPOSITION, max_neighbors=100
            )
        return self._search_api_composition

    def _get_search_api_structure(self) -> SearchAPI:
        if self._search_api_structure is None:
            self._search_api_structure = SearchAPI(
                input_type=InputType.STRUCTURE, max_neighbors=100
            )
        return self._search_api_structure

    def _get_mpr(self):
        if self._mpr is not None:
            return self._mpr
        mp_api_key = os.getenv("MP_API_KEY")
        if not mp_api_key:
            raise MissingEnvError("MP_API_KEY environment variable not set.")
        from mp_api.client import MPRester

        self._mpr = MPRester(api_key=mp_api_key)
        return self._mpr

    def find_similar_materials_by_composition(
        self, composition_str: str, n_neighbors: int = 10
    ) -> list[Neighbor]:
        composition = Composition(composition_str)
        results = self._get_search_api_composition().query(
            composition, n_neighbors=n_neighbors
        )
        return results

    def find_similar_materials_by_structure(
        self, structure: Structure, n_neighbors: int = 10
    ) -> list[Neighbor]:
        results = self._get_search_api_structure().query(
            structure, n_neighbors=n_neighbors
        )
        return results

    def get_synthesis_recipes_by_formula(self, formula: str) -> list[SynthesisRecipe]:
        mpr = self._get_mpr()
        recipes = mpr.materials.synthesis.search(target_formula=formula)
        return recipes

    def get_summarydoc_by_material_id(self, material_id: str) -> list[SummaryDoc]:
        mpr = self._get_mpr()
        summarydoc = mpr.materials.summary.search(material_ids=[material_id])
        return summarydoc

    def get_structure_by_material_id(self, material_id: str) -> Structure:
        mpr = self._get_mpr()
        structure = mpr.materials.get_structure_by_material_id(material_id)
        return structure


class SynthesisLLMAgent(SynthesisAgent):
    pass

```


================================================================================
=== FILE: src\embedding.py ===
================================================================================

```python
from enum import Enum

import numpy as np
from pymatgen.core import Structure, Composition
from matminer.featurizers.composition import ElementProperty
from mace.calculators import mace_mp


class InputType(Enum):
    COMPOSITION = "composition"
    STRUCTURE = "structure"


class MaterialsEmbedding:
    def __init__(self, input_type: InputType):
        self.input_type = input_type
        self._magpie_featurizer = None
        self._mace_calculator = None

    def _get_composition_embedding(self, composition: Composition) -> np.ndarray:
        if self._magpie_featurizer is None:
            self._magpie_featurizer = ElementProperty.from_preset("magpie")

        return np.array([self._magpie_featurizer.featurize(composition)])

    def _get_structure_embedding(self, structure: Structure) -> np.ndarray:
        if self._mace_calculator is None:
            self._mace_calculator = mace_mp()

        return np.array(
            [
                self._mace_calculator.get_descriptors(structure.to_ase_atoms()).mean(
                    axis=0
                )
            ]
        )

    def get_embedding(self, input_data: Composition | Structure) -> np.ndarray:
        if self.input_type == InputType.COMPOSITION:
            if not isinstance(input_data, Composition):
                raise ValueError("Input data must be a Composition.")
            return self._get_composition_embedding(input_data)
        elif self.input_type == InputType.STRUCTURE:
            if not isinstance(input_data, Structure):
                raise ValueError("Input data must be a Structure.")
            return self._get_structure_embedding(input_data)
        else:
            raise ValueError("Invalid input type.")

```


================================================================================
=== FILE: src\recursive_synthesis.py ===
================================================================================

```python
"""
Recursive Best-Guess Synthesis Search Algorithm

This module implements a confidence-based recursive search for synthesis recipes
when direct recipes are not available for a target material.
"""

import os
from typing import List, Dict, Optional, Set, Tuple
from dataclasses import dataclass, field
from collections import defaultdict
import numpy as np

from pymatgen.core import Composition
from .schema import Neighbor, SynthesisRecipe
from .agent import SynthesisAgent


@dataclass
class RecipeCandidate:
    """Represents a potential synthesis recipe from a neighbor material."""
    material_id: str
    formula: str
    recipe: SynthesisRecipe
    confidence: float
    distance: float
    path_length: int  # How many hops from target
    reasoning: str = ""


@dataclass 
class SearchNode:
    """Node in the recursive search tree."""
    material_id: str
    formula: str
    confidence: float
    distance: float
    depth: int
    parent: Optional['SearchNode'] = None
    children: List['SearchNode'] = field(default_factory=list)
    
    def get_path(self) -> List[str]:
        """Get the path from root to this node."""
        path = []
        node = self
        while node:
            path.append(f"{node.formula} ({node.material_id})")
            node = node.parent
        return list(reversed(path))


class RecursiveSynthesisSearch:
    """
    Implements recursive best-guess algorithm for finding synthesis recipes.
    
    The algorithm works by:
    1. Starting with a target material
    2. If no direct recipe, search neighbors with high confidence
    3. Recursively explore neighbors of neighbors with decreasing confidence threshold
    4. Aggregate found recipes weighted by confidence
    5. Synthesize best guess based on chemical similarity
    """
    
    def __init__(
        self,
        synthesis_agent: Optional[SynthesisAgent] = None,
        mpr: Optional[MPRester] = None,
        max_depth: int = 3,
        min_confidence: float = 0.7,
        confidence_decay: float = 0.85,
        max_neighbors_per_level: int = 10,
        verbose: bool = True
    ):
        """
        Initialize the recursive synthesis search.
        
        Args:
            synthesis_agent: Agent for similarity search and recipe retrieval
            mpr: Materials Project client
            max_depth: Maximum recursion depth
            min_confidence: Minimum confidence threshold to explore
            confidence_decay: How much to reduce confidence threshold per level
            max_neighbors_per_level: Max neighbors to explore at each level
            verbose: Print search progress
        """
        self.agent = synthesis_agent or SynthesisAgent()
        if mpr is not None:
            self.mpr = mpr
        else:
            mp_key = os.getenv("MP_API_KEY")
            if mp_key:
                from mp_api.client import MPRester

                self.mpr = MPRester(api_key=mp_key)
            else:
                self.mpr = None
        self.max_depth = max_depth
        self.min_confidence = min_confidence
        self.confidence_decay = confidence_decay
        self.max_neighbors_per_level = max_neighbors_per_level
        self.verbose = verbose
        
        # Track visited materials to avoid cycles
        self.visited: Set[str] = set()
        self.recipe_candidates: List[RecipeCandidate] = []
        
    def search(
        self, 
        target_formula: str,
        n_initial_neighbors: int = 30
    ) -> Dict:
        """
        Main entry point for recursive synthesis search.
        
        Args:
            target_formula: Target material composition
            n_initial_neighbors: Number of initial neighbors to consider
            
        Returns:
            Dictionary with search results and best guess synthesis
        """
        self.visited.clear()
        self.recipe_candidates.clear()
        
        if self.verbose:
            print(f"üîç Starting recursive synthesis search for {target_formula}")
        
        # Create root node
        root = SearchNode(
            material_id="target",
            formula=target_formula,
            confidence=1.0,
            distance=0.0,
            depth=0
        )
        
        # Start recursive search
        self._recursive_search(
            node=root,
            n_neighbors=n_initial_neighbors,
            confidence_threshold=1.0
        )
        
        # Aggregate and synthesize results
        results = self._synthesize_results(target_formula)
        
        return results
    
    def _recursive_search(
        self,
        node: SearchNode,
        n_neighbors: int,
        confidence_threshold: float
    ):
        """
        Recursive depth-first search for synthesis recipes.
        
        Args:
            node: Current search node
            n_neighbors: Number of neighbors to explore
            confidence_threshold: Current confidence threshold
        """
        # Check termination conditions
        if node.depth >= self.max_depth:
            if self.verbose:
                print(f"  {'  ' * node.depth}‚õî Max depth reached at {node.formula}")
            return
        
        if node.confidence < self.min_confidence:
            if self.verbose:
                print(f"  {'  ' * node.depth}‚õî Confidence too low ({node.confidence:.3f}) for {node.formula}")
            return
        
        if node.material_id in self.visited and node.material_id != "target":
            if self.verbose:
                print(f"  {'  ' * node.depth}üîÑ Already visited {node.formula}")
            return
        
        # Mark as visited
        if node.material_id != "target":
            self.visited.add(node.material_id)
        
        if self.verbose:
            print(f"  {'  ' * node.depth}üìç Exploring {node.formula} (conf={node.confidence:.3f}, depth={node.depth})")
        
        # Try to get recipes for current node
        if node.material_id != "target":
            self._check_recipes(node)
        
        # Get neighbors
        try:
            neighbors = self.agent.find_similar_materials_by_composition(
                node.formula, 
                n_neighbors=n_neighbors
            )
        except Exception as e:
            if self.verbose:
                print(f"  {'  ' * node.depth}‚ùå Error getting neighbors: {e}")
            return
        
        # Filter and sort neighbors by confidence
        filtered_neighbors = [
            n for n in neighbors 
            if n.confidence >= confidence_threshold * self.confidence_decay
            and n.material_id not in self.visited
        ]
        
        # Limit neighbors per level
        filtered_neighbors = filtered_neighbors[:self.max_neighbors_per_level]
        
        if self.verbose and filtered_neighbors:
            print(f"  {'  ' * node.depth}üîó Found {len(filtered_neighbors)} promising neighbors")
        
        # Recursively explore neighbors
        for neighbor in filtered_neighbors:
            child = SearchNode(
                material_id=neighbor.material_id,
                formula=neighbor.formula,
                confidence=neighbor.confidence,
                distance=neighbor.distance,
                depth=node.depth + 1,
                parent=node
            )
            node.children.append(child)
            
            # Recursive call with decayed threshold
            self._recursive_search(
                node=child,
                n_neighbors=max(5, n_neighbors // 2),  # Reduce neighbors as we go deeper
                confidence_threshold=confidence_threshold * self.confidence_decay
            )
    
    def _check_recipes(self, node: SearchNode):
        """
        Check if a material has synthesis recipes.
        
        Args:
            node: Search node to check
        """
        try:
            # Try to get recipes
            recipes = self.agent.get_synthesis_recipes_by_formula(node.formula)
            
            if recipes and len(recipes) > 0:
                if self.verbose:
                    print(f"  {'  ' * node.depth}‚úÖ Found {len(recipes)} recipe(s) for {node.formula}")
                
                # Add each recipe as a candidate
                for recipe in recipes[:3]:  # Limit to top 3 recipes per material
                    candidate = RecipeCandidate(
                        material_id=node.material_id,
                        formula=node.formula,
                        recipe=recipe,
                        confidence=node.confidence,
                        distance=node.distance,
                        path_length=node.depth,
                        reasoning=f"Found via path: {' ‚Üí '.join(node.get_path())}"
                    )
                    self.recipe_candidates.append(candidate)
                    
        except Exception as e:
            if self.verbose:
                print(f"  {'  ' * node.depth}‚ö†Ô∏è Could not check recipes for {node.formula}: {e}")
    
    def _synthesize_results(self, target_formula: str) -> Dict:
        """
        Aggregate and synthesize the search results into a best guess.
        
        Args:
            target_formula: Original target formula
            
        Returns:
            Dictionary with synthesis recommendations
        """
        if not self.recipe_candidates:
            return {
                "status": "no_recipes_found",
                "target": target_formula,
                "message": "No synthesis recipes found in recursive search",
                "visited_materials": len(self.visited),
                "recommendations": []
            }
        
        # Sort candidates by weighted score
        for candidate in self.recipe_candidates:
            # Weight by confidence and inverse path length
            candidate.score = candidate.confidence / (1 + 0.2 * candidate.path_length)
        
        self.recipe_candidates.sort(key=lambda x: x.score, reverse=True)
        
        # Group recipes by material
        recipes_by_material = defaultdict(list)
        for candidate in self.recipe_candidates:
            recipes_by_material[candidate.formula].append(candidate)
        
        # Create synthesis recommendations
        recommendations = []
        for formula, candidates in list(recipes_by_material.items())[:5]:  # Top 5 materials
            best_candidate = candidates[0]
            
            # Calculate adaptation strategy
            adaptation = self._calculate_adaptation(target_formula, formula)
            
            recommendations.append({
                "source_material": formula,
                "material_id": best_candidate.material_id,
                "confidence": best_candidate.confidence,
                "distance": best_candidate.distance,
                "path_length": best_candidate.path_length,
                "score": best_candidate.score,
                "num_recipes": len(candidates),
                "adaptation_strategy": adaptation,
                "reasoning": best_candidate.reasoning
            })
        
        return {
            "status": "success",
            "target": target_formula,
            "visited_materials": len(self.visited),
            "total_candidates": len(self.recipe_candidates),
            "unique_materials_with_recipes": len(recipes_by_material),
            "recommendations": recommendations,
            "best_guess": self._generate_best_guess(target_formula, recommendations)
        }
    
    def _calculate_adaptation(self, target: str, source: str) -> Dict:
        """
        Calculate how to adapt a source recipe for the target material.
        
        Args:
            target: Target formula
            source: Source formula with known recipe
            
        Returns:
            Adaptation strategy dictionary
        """
        target_comp = Composition(target)
        source_comp = Composition(source)
        
        # Get elemental differences
        target_elements = set(target_comp.elements)
        source_elements = set(source_comp.elements)
        
        added_elements = target_elements - source_elements
        removed_elements = source_elements - target_elements
        common_elements = target_elements & source_elements
        
        # Calculate stoichiometry changes
        stoich_changes = {}
        for el in common_elements:
            target_ratio = target_comp.get_atomic_fraction(el)
            source_ratio = source_comp.get_atomic_fraction(el)
            change = (target_ratio - source_ratio) / source_ratio if source_ratio > 0 else 0
            stoich_changes[str(el)] = {
                "target": target_ratio,
                "source": source_ratio,
                "change_percent": change * 100
            }
        
        return {
            "added_elements": [str(el) for el in added_elements],
            "removed_elements": [str(el) for el in removed_elements],
            "common_elements": [str(el) for el in common_elements],
            "stoichiometry_changes": stoich_changes,
            "similarity_score": len(common_elements) / max(len(target_elements), len(source_elements))
        }
    
    def _generate_best_guess(self, target: str, recommendations: List[Dict]) -> Dict:
        """
        Generate a best guess synthesis procedure based on found recipes.
        
        Args:
            target: Target formula
            recommendations: List of recipe recommendations
            
        Returns:
            Best guess synthesis dictionary
        """
        if not recommendations:
            return {"message": "No recommendations available"}
        
        best = recommendations[0]
        
        # Determine synthesis approach based on confidence
        if best["confidence"] > 0.95:
            approach = "direct_adaptation"
            confidence_level = "very_high"
        elif best["confidence"] > 0.85:
            approach = "minor_modification"
            confidence_level = "high"
        elif best["confidence"] > 0.75:
            approach = "guided_exploration"
            confidence_level = "moderate"
        else:
            approach = "experimental_optimization"
            confidence_level = "exploratory"
        
        return {
            "approach": approach,
            "confidence_level": confidence_level,
            "primary_reference": best["source_material"],
            "adaptation_required": best["adaptation_strategy"],
            "key_considerations": [
                f"Based on {best['source_material']} with {best['confidence']:.1%} confidence",
                f"Requires adapting for: {', '.join(best['adaptation_strategy']['added_elements'])}",
                f"Path length: {best['path_length']} hops from target",
                f"Explored {len(recommendations)} potential routes"
            ],
            "recommended_validation": [
                "Start with small-scale test synthesis",
                "Verify phase purity with XRD",
                "Adjust stoichiometry based on initial results",
                "Consider alternative precursors for added elements"
            ]
        }

```


================================================================================
=== FILE: src\schema.py ===
================================================================================

```python
from pydantic import BaseModel
from emmet.core.synthesis import SynthesisRecipe
from emmet.core.summary import SummaryDoc


class Neighbor(BaseModel):
    neighbor_index: int
    material_id: str
    formula: str
    distance: float
    confidence: float


__all__ = ["Neighbor", "SynthesisRecipe", "SummaryDoc"]

```


================================================================================
=== FILE: src\search_api.py ===
================================================================================

```python
import h5py
import numpy as np
from pymatgen.core import Composition, Structure
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import NearestNeighbors

from src import ASSETS_DIR
from src.utils.assets import find_asset
from src.embedding import MaterialsEmbedding, InputType
from src.schema import Neighbor


class SearchAPI:
    def __init__(
        self,
        input_type: InputType,
        max_neighbors: int = 100,
    ):
        self.featurizer = MaterialsEmbedding(input_type=input_type)
        self.max_neighbors = max_neighbors

        # Load pre-computed MP dataset
        self.mp_data = self._load_mp_data()

        # Set up nearest neighbors model
        self._set_nearest_neighbors_model()

    def _load_mp_data(self):
        if self.featurizer.input_type == InputType.COMPOSITION:
            h5_file = find_asset(
                preferred_names=["mp_dataset_composition_magpie.h5"],
                globs=["*composition*.h5"],
                base=ASSETS_DIR / "embedding",
            )
        elif self.featurizer.input_type == InputType.STRUCTURE:
            h5_file = find_asset(
                preferred_names=["mp_dataset_structure_mace.h5"],
                globs=["*structure*.h5"],
                base=ASSETS_DIR / "embedding",
            )
        else:
            raise ValueError("Invalid input type.")
        if h5_file is None:
            raise FileNotFoundError("No embedding HDF5 file found in assets/embedding")
        print(f"Loading MP dataset from {h5_file}")

        with h5py.File(h5_file, "r") as f:
            features = f["features"][:]
            material_ids = f["material_ids"][:].astype("str")
            formulas = f["formulas"][:].astype("str")

        return {
            "features": features,
            "material_ids": material_ids,
            "formulas": formulas,
        }

    def _set_nearest_neighbors_model(self):
        self.scaler = StandardScaler().fit(self.mp_data["features"])
        mp_features_scaled = self.scaler.transform(self.mp_data["features"])
        self.nn_model = NearestNeighbors(
            n_neighbors=self.max_neighbors, metric="euclidean"
        ).fit(mp_features_scaled)

    def query(
        self, input_data: Composition | Structure, n_neighbors: int = 10
    ) -> list[Neighbor]:
        input_embedding = self.featurizer.get_embedding(input_data)
        input_embedding_scaled = self.scaler.transform(input_embedding)
        distances, indices = self.nn_model.kneighbors(
            input_embedding_scaled, n_neighbors=n_neighbors
        )
        distances = distances.squeeze()
        indices = indices.squeeze()
        confidences = np.exp(-distances / 3)

        # Collect results
        results = []
        for i, idx in enumerate(indices):
            results.append(
                Neighbor(
                    neighbor_index=i,
                    material_id=self.mp_data["material_ids"][idx].item(),
                    formula=self.mp_data["formulas"][idx].item(),
                    distance=distances[i].item(),
                    confidence=confidences[i].item(),
                )
            )
        return results

```


================================================================================
=== FILE: src\__init__.py ===
================================================================================

```python
from pathlib import Path

PROJECT_ROOT = Path(__file__).resolve().parent.parent
ASSETS_DIR = PROJECT_ROOT / "assets"

```


================================================================================
=== FILE: src\utils\assets.py ===
================================================================================

```python
from __future__ import annotations

from pathlib import Path
from typing import Iterable, Optional


def find_asset(
    preferred_names: Iterable[str],
    globs: Iterable[str],
    base: Path,
) -> Optional[Path]:
    if not base.exists():
        return None
    for name in preferred_names:
        candidate = base / name
        if candidate.exists():
            return candidate
    for pattern in globs:
        matches = sorted(base.glob(pattern))
        for match in matches:
            if match.is_file():
                return match
    return None

```


================================================================================
=== FILE: src\utils\get_mp_embedding.py ===
================================================================================

```python
from pathlib import Path
import h5py
import numpy as np

from monty.serialization import loadfn
from matminer.featurizers.composition import ElementProperty


dir_assets = Path(".").resolve().parent.parent / "assets/embedding"
mp_data = loadfn(dir_assets / "mp_dataset_only_GGA.json.gz")
print(f"Read {len(mp_data)} materials from mp_dataset_only_GGA.json.gz")

# Composition Embedding
comps = [d["structure"].composition for d in mp_data]
formulas = [d["formula_pretty"] for d in mp_data]
material_ids = [d["material_id"] for d in mp_data]
featurizer = ElementProperty.from_preset("magpie")
features = np.array(featurizer.featurize_many(comps))
print(f"Shape of features: {features.shape}")

h5_file = dir_assets / "mp_dataset_composition_magpie.h5"
with h5py.File(h5_file, "w") as f:
    f.create_dataset("features", data=features, compression="gzip")
    f.create_dataset("material_ids", data=material_ids, compression="gzip")
    f.create_dataset("formulas", data=formulas, compression="gzip")
print(f"Saved features and material_ids to {h5_file}")
# with h5py.File(h5_file, "r") as f:
#     features = f["features"][:]
#     material_ids = f["material_ids"][:].astype("str")
#     formulas = f["formulas"][:].astype("str")

```


================================================================================
=== FILE: src\utils\__init__.py ===
================================================================================

```python

```


================================================================================
=== FILE: tests\conftest.py ===
================================================================================

```python
from __future__ import annotations

import sys
from pathlib import Path

REPO_ROOT = Path(__file__).resolve().parents[1]
if str(REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(REPO_ROOT))

```


================================================================================
=== FILE: tests\test_mcp_hardening.py ===
================================================================================

```python
from __future__ import annotations

from pathlib import Path

import pytest

from sky_mcp import tools
from sky_mcp.report_io import atomic_write_text, build_report_path
from sky_mcp.response import validate_envelope


def test_envelope_invariants_all_tools(tmp_path, monkeypatch):
    monkeypatch.setenv("SKY_MCP_ALLOWED_ROOTS", str(tmp_path))

    cases = [
        tools.capabilities(),
        tools.self_check(),
        tools.read_cif("not a cif"),
        tools.read_cif_path(str(tmp_path / "missing.cif")),
        tools.search_similar_by_composition(""),
        tools.search_similar_by_structure_cif("not a cif"),
        tools.search_similar_by_structure_path(str(tmp_path / "missing.cif")),
        tools.get_material_properties([]),
        tools.get_synthesis_recipes(""),
        tools.analyze_synthesis_parameters(""),
        tools.recursive_synthesis_search(""),
    ]

    for resp in cases:
        validate_envelope(resp, strict=True)


def test_determinism_sorted_lists():
    resp = tools.capabilities()
    assets = resp["data"]["assets"]["files"]
    for key, value in assets.items():
        assert value == sorted(value), f"{key} is not sorted"


def test_path_traversal_rejected():
    resp = tools.read_cif_path("../../etc/passwd")
    assert resp["ok"] is False
    assert resp["error"]["type"] in {"permission_denied", "invalid_input"}


def test_file_too_large_rejected(tmp_path, monkeypatch):
    monkeypatch.setenv("SKY_MCP_ALLOWED_ROOTS", str(tmp_path))
    big_file = tmp_path / "big.cif"
    big_file.write_bytes(b"0" * 2_000_001)
    resp = tools.read_cif_path(str(big_file))
    assert resp["ok"] is False
    assert resp["error"]["type"] == "file_too_large"


def test_report_path_relative(tmp_path, monkeypatch):
    class _FixedUUID:
        def __str__(self):
            return "fixed-uuid"

    reports_dir = tmp_path / "sky_reports"
    path = build_report_path("Fe2O3", reports_dir, uuid_func=_FixedUUID)
    atomic_write_text(path, "<html>ok</html>")
    rel = path.relative_to(tmp_path)
    assert str(rel).startswith("sky_reports")

```


================================================================================
=== FILE: tests\test_mcp_import.py ===
================================================================================

```python
def test_import_server_without_env(monkeypatch):
    monkeypatch.delenv("MP_API_KEY", raising=False)
    monkeypatch.delenv("OPENAI_API_KEY", raising=False)
    monkeypatch.delenv("OPENAI_MDG_API_KEY", raising=False)

    import importlib

    import sky_mcp.server

    importlib.reload(sky_mcp.server)

```


================================================================================
=== FILE: tests\test_mcp_tools.py ===
================================================================================

```python
from sky_mcp import tools


def test_analyze_synthesis_parameters():
    result = tools.analyze_synthesis_parameters("Heat at 800 C for 10 hours in air.")
    assert result["ok"] is True
    data = result["data"]
    assert "temperatures_C" in data
    assert "time_durations" in data
    assert "synthesis_methods" in data
    assert "atmosphere" in data


def test_read_cif_invalid_text():
    result = tools.read_cif("not a cif")
    assert result["ok"] is False
    assert result["error"]["type"] in {"invalid_input", "runtime_error"}


def test_read_cif_path_missing(tmp_path, monkeypatch):
    missing = tmp_path / "missing.cif"
    monkeypatch.setenv("SKY_MCP_ALLOWED_ROOTS", str(tmp_path))
    result = tools.read_cif_path(str(missing))
    assert result["ok"] is False
    assert result["error"]["type"] == "file_not_found"


def test_search_similar_by_structure_cif_missing_assets(monkeypatch):
    cif_text = """data_test
_symmetry_space_group_name_H-M 'P 1'
_cell_length_a   3.0
_cell_length_b   3.0
_cell_length_c   3.0
_cell_angle_alpha 90
_cell_angle_beta  90
_cell_angle_gamma 90
_symmetry_Int_Tables_number 1
_chemical_formula_sum 'H2 O1'
loop_
_atom_site_label
_atom_site_type_symbol
_atom_site_fract_x
_atom_site_fract_y
_atom_site_fract_z
H1 H 0 0 0
H2 H 0.5 0.5 0.5
O1 O 0.25 0.25 0.25
"""
    monkeypatch.setattr(tools, "_structure_embedding_path", lambda: None)
    result = tools.search_similar_by_structure_cif(cif_text)
    assert result["ok"] is False
    assert result["error"]["type"] == "file_not_found"

```


################################################################################
# MANIFEST
# Included files:
#  - project_context.txt
#  - project_to_txt.py
#  - pyproject.toml
#  - README.md
#  - requirements.txt
#  - tutorial.ipynb
#  - figs\recipy.ipynb
#  - pytest-cache-files-5q98j3cp\CACHEDIR.TAG
#  - pytest-cache-files-5q98j3cp\README.md
#  - pytest-cache-files-9v9c2uav\CACHEDIR.TAG
#  - pytest-cache-files-9v9c2uav\README.md
#  - pytest-cache-files-be92m6jh\CACHEDIR.TAG
#  - pytest-cache-files-be92m6jh\README.md
#  - pytest-cache-files-ckstj4qg\CACHEDIR.TAG
#  - pytest-cache-files-ckstj4qg\README.md
#  - pytest-cache-files-d2kqjecr\CACHEDIR.TAG
#  - pytest-cache-files-d2kqjecr\README.md
#  - pytest-cache-files-q02twmza\CACHEDIR.TAG
#  - pytest-cache-files-q02twmza\README.md
#  - pytest-cache-files-qy_idee7\CACHEDIR.TAG
#  - pytest-cache-files-qy_idee7\README.md
#  - pytest-cache-files-s7elq7ls\CACHEDIR.TAG
#  - pytest-cache-files-s7elq7ls\README.md
#  - pytest-cache-files-sx9_8emy\CACHEDIR.TAG
#  - pytest-cache-files-sx9_8emy\README.md
#  - pytest-cache-files-tegjyoar\CACHEDIR.TAG
#  - pytest-cache-files-tegjyoar\README.md
#  - pytest-cache-files-ui9s2k53\CACHEDIR.TAG
#  - pytest-cache-files-ui9s2k53\README.md
#  - pytest-cache-files-ur75bldd\CACHEDIR.TAG
#  - pytest-cache-files-ur75bldd\README.md
#  - pytest-cache-files-vp9266e_\CACHEDIR.TAG
#  - pytest-cache-files-vp9266e_\README.md
#  - pytest-cache-files-y5fc802v\CACHEDIR.TAG
#  - pytest-cache-files-y5fc802v\README.md
#  - sky\__init__.py
#  - sky\cli\main.py
#  - sky\cli\__init__.py
#  - sky\core\synthesis_agent.py
#  - sky\core\__init__.py
#  - sky\report\html_generator.py
#  - sky\report\__init__.py
#  - sky_mcp\paths.py
#  - sky_mcp\report_io.py
#  - sky_mcp\response.py
#  - sky_mcp\server.py
#  - sky_mcp\tools.py
#  - sky_mcp\__init__.py
#  - src\agent.py
#  - src\embedding.py
#  - src\recursive_synthesis.py
#  - src\schema.py
#  - src\search_api.py
#  - src\__init__.py
#  - src\utils\assets.py
#  - src\utils\get_mp_embedding.py
#  - src\utils\__init__.py
#  - tests\conftest.py
#  - tests\test_mcp_hardening.py
#  - tests\test_mcp_import.py
#  - tests\test_mcp_tools.py
#
# Skips summary:
#  dir: 8
#  hidden: 18
#  size: 1
#  binary: 2
#  ext: 3
#  other: 0
# END
